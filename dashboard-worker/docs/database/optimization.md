# 🚀 Fire22 Dashboard - Database Optimization v4.0.0-staging

## Overview

Comprehensive database optimization strategies for Fire22 Dashboard using SQLite
(development) and Cloudflare D1 (production) with performance monitoring, query
optimization, and cache management.

## Table of Contents

- [Performance Overview](#performance-overview)
- [Query Optimization](#query-optimization)
- [Index Management](#index-management)
- [Cache Strategies](#cache-strategies)
- [Connection Pooling](#connection-pooling)
- [Monitoring & Metrics](#monitoring--metrics)
- [SQLite Optimization](#sqlite-optimization)
- [Cloudflare D1 Optimization](#cloudflare-d1-optimization)
- [Performance Benchmarks](#performance-benchmarks)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)

---

## Performance Overview

### Current Performance Metrics

- **Query Response Time**: < 50ms average
- **Cache Hit Rate**: 85%+ target
- **Concurrent Connections**: 20 max (PostgreSQL dev), Unlimited (D1 prod)
- **Database Size**: ~500MB (dev), Scalable (D1)
- **Transaction Throughput**: 1,000+ TPS

### Architecture Overview

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Application   │───▶│   Cache Layer   │───▶│   Database     │
│                 │    │  (Fire22Cache)  │    │  SQLite/D1     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
   Request Handler       In-Memory Cache           Optimized Storage
   Connection Pool       30s TTL Default          Indexed Queries
   Error Handling        Auto-Cleanup             Transaction Safety
```

---

## Query Optimization

### Optimized Query Patterns

#### 1. **Customer Queries**

```sql
-- ❌ Unoptimized
SELECT * FROM customers WHERE name LIKE '%john%';

-- ✅ Optimized
SELECT id, name, email, status, balance
FROM customers
WHERE name LIKE 'john%'
AND status = 'active'
ORDER BY created_at DESC
LIMIT 50;
```

#### 2. **Agent Hierarchy Queries**

```sql
-- ❌ Unoptimized
SELECT * FROM agents WHERE commission_rate > 0.05;

-- ✅ Optimized with index
SELECT id, name, code, commission_rate, total_volume
FROM agents
WHERE status = 'active'
AND commission_rate BETWEEN 0.05 AND 0.15
ORDER BY total_volume DESC;
```

#### 3. **Wager Queries with Joins**

```sql
-- ❌ Unoptimized
SELECT w.*, c.name, a.name
FROM wagers w, customers c, agents a
WHERE w.customer_id = c.id AND w.agent_id = a.id;

-- ✅ Optimized with proper JOINs
SELECT w.id, w.amount, w.status, c.name as customer_name, a.name as agent_name
FROM wagers w
INNER JOIN customers c ON w.customer_id = c.id
INNER JOIN agents a ON w.agent_id = a.id
WHERE w.status IN ('pending', 'active')
AND w.created_at >= date('now', '-7 days')
ORDER BY w.created_at DESC
LIMIT 100;
```

### Query Analysis Tools

```sql
-- SQLite Query Plan Analysis
EXPLAIN QUERY PLAN
SELECT w.id, w.amount, c.name
FROM wagers w
JOIN customers c ON w.customer_id = c.id
WHERE w.status = 'active';

-- Index Usage Statistics
SELECT name, sql FROM sqlite_master WHERE type='index';
ANALYZE;
SELECT * FROM sqlite_stat1;
```

### Parameterized Queries

```javascript
// ✅ Safe and optimized parameterized queries
async function getCustomerWagers(customerId, limit = 50) {
  const sql = `
    SELECT id, amount, description, status, created_at
    FROM wagers 
    WHERE customer_id = ? 
    AND status IN ('pending', 'active', 'settled')
    ORDER BY created_at DESC 
    LIMIT ?
  `;

  return await cache.query(sql, [customerId, limit], 30000); // 30s cache
}
```

---

## Index Management

### Essential Indexes

#### Primary Performance Indexes

```sql
-- Customer table indexes
CREATE INDEX IF NOT EXISTS idx_customers_agent_id ON customers(agent_id);
CREATE INDEX IF NOT EXISTS idx_customers_email ON customers(email);
CREATE INDEX IF NOT EXISTS idx_customers_status ON customers(status);
CREATE INDEX IF NOT EXISTS idx_customers_created_at ON customers(created_at);

-- Wagers table indexes
CREATE INDEX IF NOT EXISTS idx_wagers_customer_id ON wagers(customer_id);
CREATE INDEX IF NOT EXISTS idx_wagers_agent_id ON wagers(agent_id);
CREATE INDEX IF NOT EXISTS idx_wagers_status ON wagers(status);
CREATE INDEX IF NOT EXISTS idx_wagers_created_at ON wagers(created_at);
CREATE INDEX IF NOT EXISTS idx_wagers_wager_number ON wagers(wager_number);

-- Composite indexes for common queries
CREATE INDEX IF NOT EXISTS idx_wagers_customer_status ON wagers(customer_id, status);
CREATE INDEX IF NOT EXISTS idx_wagers_agent_status ON wagers(agent_id, status);
CREATE INDEX IF NOT EXISTS idx_wagers_status_created ON wagers(status, created_at);
```

#### Transaction Table Indexes

```sql
-- Transaction performance indexes
CREATE INDEX IF NOT EXISTS idx_transactions_customer_id ON transactions(customer_id);
CREATE INDEX IF NOT EXISTS idx_transactions_type ON transactions(type);
CREATE INDEX IF NOT EXISTS idx_transactions_status ON transactions(status);
CREATE INDEX IF NOT EXISTS idx_transactions_created_at ON transactions(created_at);
CREATE INDEX IF NOT EXISTS idx_transactions_customer_type ON transactions(customer_id, type);
```

### Index Monitoring

```sql
-- Check index effectiveness
SELECT
  name as index_name,
  tbl as table_name,
  stat as usage_stats
FROM sqlite_stat1
ORDER BY name;

-- Identify missing indexes (development)
EXPLAIN QUERY PLAN SELECT * FROM wagers WHERE status = 'pending';
```

### Index Maintenance Commands

```bash
# Analyze database statistics
sqlite3 database.db "ANALYZE;"

# Rebuild indexes
sqlite3 database.db "REINDEX;"

# Check database integrity
sqlite3 database.db "PRAGMA integrity_check;"
```

---

## Cache Strategies

### Fire22Cache Implementation

The Fire22Cache class provides intelligent caching with automatic cleanup:

```javascript
class Fire22Cache {
  private cache = new Map<string, CacheEntry<any>>();
  private defaultTTL = 30_000; // 30 seconds
  private cacheHits = 0;
  private cacheMisses = 0;

  // Intelligent cache with factory pattern
  async get<T>(key: string, factory: () => Promise<T>, ttl = this.defaultTTL): Promise<T> {
    const now = Date.now();
    const hit = this.cache.get(key);

    if (hit && hit.expires > now) {
      this.cacheHits++;
      return hit.data;
    }

    this.cacheMisses++;
    const data = await factory();
    this.cache.set(key, { data, expires: now + ttl });
    return data;
  }

  // Database query caching
  async query<T>(sql: string, params?: any[], ttl = this.defaultTTL): Promise<T[]> {
    const cacheKey = sql + JSON.stringify(params || []);
    return this.get(cacheKey, async () => {
      const { results } = await this.db.prepare(sql).bind(...(params || [])).all();
      return results as T[];
    }, ttl);
  }
}
```

### Cache TTL Strategy

| Data Type     | TTL        | Reason                                    |
| ------------- | ---------- | ----------------------------------------- |
| Customer Data | 5 minutes  | Moderate change frequency                 |
| Agent Data    | 10 minutes | Infrequent changes                        |
| Wager Data    | 30 seconds | High change frequency                     |
| System Config | 1 hour     | Very infrequent changes                   |
| Reports       | 2 minutes  | Balance between freshness and performance |

### Cache Warming Strategies

```javascript
// Proactive cache warming for frequently accessed data
async function warmCache() {
  const cache = new Fire22Cache(db);

  // Warm customer cache
  await cache.query(
    'SELECT id, name, status FROM customers WHERE status = ?',
    ['active'],
    300000
  );

  // Warm agent hierarchy cache
  await cache.query(
    'SELECT id, name, code FROM agents WHERE status = ?',
    ['active'],
    600000
  );

  // Warm active wagers cache
  await cache.query(
    'SELECT id, customer_id, status FROM wagers WHERE status IN (?, ?)',
    ['pending', 'active'],
    30000
  );
}
```

---

## Connection Pooling

### PostgreSQL Development Configuration

```javascript
// Enhanced connection pool configuration
const poolConfig = {
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,

  // Performance settings
  max: 20, // Maximum connections
  min: 2, // Minimum connections
  idleTimeoutMillis: 30000, // 30 seconds idle timeout
  connectionTimeoutMillis: 5000, // 5 seconds connection timeout
  acquireTimeoutMillis: 10000, // 10 seconds acquire timeout

  // Health checks
  testOnBorrow: true,
  testOnReturn: false,
  testWhileIdle: true,
  numTestsPerRun: 3,
  timeBetweenEvictionRunsMillis: 30000,

  // Error handling
  errorHandler: error => {
    console.error('Database pool error:', error);
  },
};
```

### Connection Monitoring

```javascript
// Connection pool health monitoring
function monitorConnectionPool(pool) {
  setInterval(() => {
    const stats = {
      totalConnections: pool.totalCount,
      activeConnections: pool.activeCount,
      idleConnections: pool.idleCount,
      waitingRequests: pool.waitingCount,
    };

    console.log('Pool Stats:', stats);

    // Alert if pool is under stress
    if (pool.waitingCount > 5) {
      console.warn('Connection pool under stress:', stats);
    }
  }, 60000); // Check every minute
}
```

---

## Monitoring & Metrics

### Database Performance Metrics

```javascript
// Comprehensive database monitoring
class DatabaseMonitor {
  private queryTimes = new Map();
  private slowQueries = [];

  async trackQuery(sql: string, params: any[], executor: () => Promise<any>) {
    const startTime = Date.now();

    try {
      const result = await executor();
      const duration = Date.now() - startTime;

      this.recordQueryTime(sql, duration);

      // Track slow queries (> 100ms)
      if (duration > 100) {
        this.slowQueries.push({
          sql: sql.substring(0, 100) + '...',
          params,
          duration,
          timestamp: new Date().toISOString()
        });
      }

      return result;
    } catch (error) {
      console.error('Query failed:', { sql, params, error: error.message });
      throw error;
    }
  }

  getStats() {
    return {
      averageQueryTime: this.calculateAverageQueryTime(),
      slowQueries: this.slowQueries.slice(-10), // Last 10 slow queries
      totalQueries: this.queryTimes.size
    };
  }
}
```

### Performance Dashboard Endpoint

```bash
# Get database performance metrics
curl -s http://localhost:3001/api/database/stats | jq

# Sample response
{
  "cache": {
    "hitRate": "87.3%",
    "cacheSize": 245,
    "cacheHits": 1247,
    "cacheMisses": 181
  },
  "queries": {
    "averageTime": 23.5,
    "slowQueries": 3,
    "totalQueries": 1428
  },
  "connections": {
    "active": 5,
    "idle": 3,
    "total": 8
  }
}
```

---

## SQLite Optimization

### SQLite-Specific Optimizations

```sql
-- Performance pragmas for SQLite
PRAGMA journal_mode = WAL;          -- Write-Ahead Logging
PRAGMA synchronous = NORMAL;        -- Balanced durability/performance
PRAGMA cache_size = 10000;          -- 10MB cache
PRAGMA temp_store = MEMORY;         -- Memory for temporary tables
PRAGMA mmap_size = 268435456;       -- 256MB memory mapping

-- Optimize for read-heavy workloads
PRAGMA optimize;                    -- Run query optimizer
PRAGMA analysis_limit = 1000;      -- Limit analysis depth
```

### SQLite Maintenance

```bash
# Database maintenance script
#!/bin/bash

# Vacuum database (compact and defragment)
sqlite3 database.db "VACUUM;"

# Update query planner statistics
sqlite3 database.db "ANALYZE;"

# Check database integrity
sqlite3 database.db "PRAGMA integrity_check;"

# Optimize database
sqlite3 database.db "PRAGMA optimize;"

echo "Database maintenance completed"
```

### SQLite Performance Tips

1. **Use WAL Mode**: Better concurrent read performance
2. **Increase Cache Size**: More memory = fewer disk I/O
3. **Regular VACUUM**: Keeps database compact
4. **Prepared Statements**: Reduces parsing overhead
5. **Batch Transactions**: Group multiple operations

---

## Cloudflare D1 Optimization

### D1-Specific Best Practices

#### Efficient Query Patterns

```javascript
// ✅ Optimized D1 queries
async function getCustomersByAgent(agentId, limit = 50) {
  // Use D1's prepare() method for parameterized queries
  const stmt = db.prepare(`
    SELECT id, name, email, status, balance
    FROM customers 
    WHERE agent_id = ? AND status = 'active'
    ORDER BY created_at DESC 
    LIMIT ?
  `);

  const { results } = await stmt.bind(agentId, limit).all();
  return results;
}

// ✅ Batch operations for efficiency
async function batchInsertWagers(wagers) {
  const stmt = db.prepare(`
    INSERT INTO wagers (wager_number, customer_id, agent_id, amount, description)
    VALUES (?, ?, ?, ?, ?)
  `);

  // D1 supports batching for better performance
  const batch = wagers.map(w =>
    stmt.bind(w.number, w.customerId, w.agentId, w.amount, w.description)
  );
  return await db.batch(batch);
}
```

#### D1 Transaction Handling

```javascript
// D1 transaction pattern
async function processWagerSettlement(wagerId, result) {
  try {
    // D1 doesn't support traditional transactions, but we can use prepare() for consistency
    const updateWager = db.prepare(`
      UPDATE wagers 
      SET status = 'settled', result = ?, settled_at = CURRENT_TIMESTAMP
      WHERE id = ?
    `);

    const insertTransaction = db.prepare(`
      INSERT INTO transactions (customer_id, type, amount, reference)
      SELECT customer_id, 'settlement', potential_win, ?
      FROM wagers WHERE id = ?
    `);

    // Execute in sequence for data consistency
    await updateWager.bind(result, wagerId).run();
    await insertTransaction.bind(`wager_${wagerId}`, wagerId).run();
  } catch (error) {
    console.error('Settlement failed:', error);
    throw error;
  }
}
```

### D1 Limitations & Workarounds

1. **No Transactions**: Use application-level consistency
2. **Limited Joins**: Optimize with indexed lookups
3. **No Stored Procedures**: Implement in application logic
4. **Read Replicas**: Leverage edge caching

---

## Performance Benchmarks

### Target Performance Metrics

| Operation         | Target Time | Current Performance |
| ----------------- | ----------- | ------------------- |
| Customer Lookup   | < 10ms      | 8.3ms avg           |
| Agent Hierarchy   | < 20ms      | 15.7ms avg          |
| Wager Creation    | < 50ms      | 42.1ms avg          |
| Report Generation | < 500ms     | 380ms avg           |
| Cache Hit         | < 1ms       | 0.3ms avg           |

### Benchmark Test Suite

```javascript
// Performance benchmark tests
async function runPerformanceBenchmarks() {
  const results = [];

  // Customer query benchmark
  const customerStart = Date.now();
  await db
    .prepare('SELECT * FROM customers WHERE status = ?')
    .bind('active')
    .all();
  results.push({ test: 'customer_query', time: Date.now() - customerStart });

  // Wager join benchmark
  const wagerStart = Date.now();
  await db
    .prepare(
      `
    SELECT w.id, w.amount, c.name 
    FROM wagers w 
    JOIN customers c ON w.customer_id = c.id 
    LIMIT 100
  `
    )
    .all();
  results.push({ test: 'wager_join', time: Date.now() - wagerStart });

  return results;
}
```

### Continuous Performance Monitoring

```bash
# Automated performance monitoring
#!/bin/bash

# Run daily performance tests
curl -X POST http://localhost:3001/api/database/benchmark

# Generate performance report
curl -s http://localhost:3001/api/database/performance-report | jq > daily_report.json

# Alert if performance degrades
RESPONSE_TIME=$(curl -s http://localhost:3001/api/database/stats | jq '.queries.averageTime')
if (( $(echo "$RESPONSE_TIME > 50" | bc -l) )); then
  echo "ALERT: Database response time ${RESPONSE_TIME}ms exceeds threshold"
fi
```

---

## Best Practices

### Query Design Principles

1. **Select Only Needed Columns**: Avoid `SELECT *`
2. **Use Appropriate Indexes**: Match WHERE clauses to indexes
3. **Limit Result Sets**: Always use LIMIT for large queries
4. **Optimize JOINs**: Use INNER JOIN when possible
5. **Cache Frequently Accessed Data**: Implement intelligent caching

### Schema Design Guidelines

1. **Normalize Appropriately**: Balance normalization vs. query complexity
2. **Use Appropriate Data Types**: Choose efficient data types
3. **Add Constraints**: Ensure data integrity
4. **Plan for Growth**: Design scalable schemas
5. **Document Relationships**: Clear foreign key relationships

### Monitoring & Alerting

```javascript
// Performance alerting system
function setupPerformanceAlerts() {
  setInterval(async () => {
    const stats = await db.getPerformanceStats();

    // Alert on high response times
    if (stats.averageResponseTime > 100) {
      console.warn('High database response time:', stats.averageResponseTime);
    }

    // Alert on low cache hit rate
    if (stats.cacheHitRate < 0.8) {
      console.warn('Low cache hit rate:', stats.cacheHitRate);
    }

    // Alert on connection pool exhaustion
    if (stats.connectionPoolUtilization > 0.9) {
      console.error(
        'Connection pool near exhaustion:',
        stats.connectionPoolUtilization
      );
    }
  }, 60000); // Check every minute
}
```

---

## Troubleshooting

### Common Performance Issues

#### 1. **Slow Queries**

**Symptoms**: High response times, timeout errors **Diagnosis**:

```sql
-- Check query execution plan
EXPLAIN QUERY PLAN SELECT * FROM wagers WHERE status = 'pending';

-- Check if indexes are being used
SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='wagers';
```

**Solutions**:

- Add missing indexes
- Optimize WHERE clauses
- Reduce result set size
- Use parameterized queries

#### 2. **High Memory Usage**

**Symptoms**: Out of memory errors, slow performance **Diagnosis**:

```bash
# Check cache size
curl -s http://localhost:3001/api/cache/stats

# Monitor memory usage
ps aux | grep node
```

**Solutions**:

- Implement cache cleanup
- Reduce cache TTL
- Optimize query result sets
- Add memory limits

#### 3. **Connection Pool Exhaustion**

**Symptoms**: Connection timeout errors **Diagnosis**:

```bash
# Check connection pool status
curl -s http://localhost:3001/api/database/pool-stats
```

**Solutions**:

- Increase pool size
- Reduce connection timeout
- Fix connection leaks
- Implement connection monitoring

### Debug Commands

```bash
# Database performance analysis
curl -s http://localhost:3001/api/database/analyze | jq

# Cache performance
curl -s http://localhost:3001/api/cache/performance | jq

# Connection pool health
curl -s http://localhost:3001/api/database/connections | jq

# Slow query analysis
curl -s http://localhost:3001/api/database/slow-queries | jq
```

### Recovery Procedures

```bash
# Emergency database recovery
#!/bin/bash

# 1. Stop application
pkill -f "node.*fire22"

# 2. Backup current database
cp database.db database_backup_$(date +%Y%m%d_%H%M%S).db

# 3. Run integrity check
sqlite3 database.db "PRAGMA integrity_check;"

# 4. Rebuild indexes if needed
sqlite3 database.db "REINDEX;"

# 5. Vacuum database
sqlite3 database.db "VACUUM;"

# 6. Restart application
bun run dev:hmr

echo "Database recovery completed"
```

---

## Maintenance Schedule

### Daily Tasks

- ✅ Monitor query performance
- ✅ Check cache hit rates
- ✅ Review slow query logs
- ✅ Monitor connection pool health

### Weekly Tasks

- ✅ Run ANALYZE to update statistics
- ✅ Review and optimize slow queries
- ✅ Clean up old cache entries
- ✅ Performance benchmark tests

### Monthly Tasks

- ✅ VACUUM database (SQLite)
- ✅ Review and update indexes
- ✅ Performance trend analysis
- ✅ Capacity planning review

### Quarterly Tasks

- ✅ Full database backup and restore test
- ✅ Schema optimization review
- ✅ Security audit
- ✅ Disaster recovery drill

---

_Last Updated: 2025-08-28_ _Version: 4.0.0-staging_ _Database Optimization Guide
for Fire22 Dashboard_
