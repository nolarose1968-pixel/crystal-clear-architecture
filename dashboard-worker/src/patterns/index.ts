// ╭─────────────────────────────────────────────────────────────────╮
// │                    🕸️ PATTERN SYSTEM INDEX                     │
// │              The Central Hub of Pattern Weaving               │
// ╰─────────────────────────────────────────────────────────────────╯

export { PatternWeaver, patternWeaver } from './pattern-weaver';
export { PatternConnector, withPattern, UsePattern } from './pattern-connector';
export { ShellPatternWeaver, shellWeaver } from './shell-weaver';

import { patternWeaver } from './pattern-weaver';
import PatternConnector from './pattern-connector';
import type { TabularResult } from './pattern-weaver';

// ╭─────────────────────────────────────────────────────────────────╮
// │                   Pattern Registry                            │
// ╰─────────────────────────────────────────────────────────────────╯

/**
 * Central registry of all patterns in the system
 * This creates the tapestry that connects everything
 */
export const PatternRegistry = {
  // Core patterns from Bun features
  patterns: {
    LOADER: '📂 File Loading',
    STYLER: '🎨 CSS Processing', 
    TABULAR: '📊 Data Tables',
    SECURE: '🔐 Secrets Management',
    TIMING: '⏱️ Performance Measurement',
    BUILDER: '🔨 Build Process',
    VERSIONER: '📦 Version Management',
    SHELL: '🐚 Shell Command Execution',
    BUNX: '📦 Package Execution',
    INTERACTIVE: '🎯 Interactive CLI',
    STREAM: '🌊 Stream Processing',
    FILESYSTEM: '📁 File System Operations',
    UTILITIES: '🔧 Utility Functions'
  },
  
  // Pattern connections map
  connections: new Map<string, string[]>([
    ['API', ['LOADER', 'SECURE', 'TIMING', 'TABULAR']],
    ['DATABASE', ['LOADER', 'TABULAR', 'TIMING']],
    ['BUILD', ['BUILDER', 'VERSIONER', 'TIMING', 'SHELL']],
    ['AUTH', ['SECURE', 'VERSIONER']],
    ['STYLES', ['STYLER', 'LOADER', 'BUILDER']],
    ['CONFIG', ['LOADER', 'VERSIONER']],
    ['MONITORING', ['TIMING', 'TABULAR']],
    ['REPORTS', ['TABULAR', 'TIMING', 'LOADER']],
    ['AUTOMATION', ['SHELL', 'BUNX', 'TIMING']],
    ['DEPLOYMENT', ['SHELL', 'BUILDER', 'SECURE', 'VERSIONER']],
    ['DEVELOPMENT', ['BUNX', 'SHELL', 'TIMING', 'TABULAR']],
    ['TOOLS', ['BUNX', 'SHELL', 'LOADER']],
    ['CLI', ['INTERACTIVE', 'SHELL', 'TABULAR', 'TIMING']],
    ['PIPES', ['STREAM', 'TIMING', 'TABULAR']],
    ['INPUT', ['INTERACTIVE', 'STREAM', 'SECURE']],
    ['VALIDATION', ['FILESYSTEM', 'TIMING', 'TABULAR']],
    ['FILES', ['FILESYSTEM', 'LOADER', 'SECURE']],
    ['TEXT', ['UTILITIES', 'TABULAR', 'TIMING']],
    ['COMPRESSION', ['UTILITIES', 'FILESYSTEM', 'TIMING']],
    ['DEBUGGING', ['UTILITIES', 'TIMING', 'TABULAR', 'INTERACTIVE']],
    ['PERFORMANCE', ['UTILITIES', 'TIMING', 'TABULAR']]
  ]),
  
  // Get patterns for a context
  getPatternsForContext(context: string): string[] {
    return this.connections.get(context.toUpperCase()) || [];
  },
  
  // Check if patterns are connected
  areConnected(pattern1: string, pattern2: string): boolean {
    for (const [_, patterns] of this.connections) {
      if (patterns.includes(pattern1) && patterns.includes(pattern2)) {
        return true;
      }
    }
    return false;
  }
};

// ╭─────────────────────────────────────────────────────────────────╮
// │                    Pattern Utilities                          │
// ╰─────────────────────────────────────────────────────────────────╯

/**
 * Utility functions for working with patterns
 */
export const PatternUtils = {
  /**
   * Apply multiple patterns in sequence
   */
  async chain(...patterns: Array<{ pattern: string; context: any }>) {
    const results = [];
    
    for (const { pattern, context } of patterns) {
      const result = await patternWeaver.applyPattern(pattern as any, context);
      results.push({ pattern, result });
    }
    
    return results;
  },
  
  /**
   * Apply patterns in parallel
   */
  async parallel(...patterns: Array<{ pattern: string; context: any }>) {
    const promises = patterns.map(({ pattern, context }) =>
      patternWeaver.applyPattern(pattern as any, context)
        .then(result => ({ pattern, result }))
    );
    
    return await Promise.all(promises);
  },
  
  /**
   * Create a pattern pipeline
   */
  pipeline(...patterns: string[]) {
    return async (initialContext: any) => {
      let context = initialContext;
      
      for (const pattern of patterns) {
        context = await patternWeaver.applyPattern(pattern as any, context);
      }
      
      return context;
    };
  },
  
  /**
   * Measure pattern performance
   */
  async benchmark(pattern: string, context: any, iterations = 1000) {
    const timings: number[] = [];
    
    for (let i = 0; i < iterations; i++) {
      const start = Bun.nanoseconds();
      await patternWeaver.applyPattern(pattern as any, context);
      const end = Bun.nanoseconds();
      timings.push(end - start);
    }
    
    const avg = timings.reduce((a, b) => a + b, 0) / timings.length;
    const min = Math.min(...timings);
    const max = Math.max(...timings);
    
    return {
      pattern,
      iterations,
      avg: `${(avg / 1_000_000).toFixed(3)}ms`,
      min: `${(min / 1_000_000).toFixed(3)}ms`,
      max: `${(max / 1_000_000).toFixed(3)}ms`
    };
  }
};

// ╭─────────────────────────────────────────────────────────────────╮
// │                  Pattern Initialization                       │
// ╰─────────────────────────────────────────────────────────────────╯

/**
 * Initialize the entire pattern system
 */
export async function initializePatterns() {
  
  // Initialize pattern connections
  await PatternConnector.initialize();
  
  // Display pattern registry
  const registryTable = Object.entries(PatternRegistry.patterns).map(([key, name]) => ({
    Pattern: key,
    Description: name,
    Connections: PatternRegistry.connections.get(key.split('_')[0])?.length || 0
  }));
  
  // Show pattern contexts
  const contextTable = Array.from(PatternRegistry.connections.entries()).map(([context, patterns]) => ({
    Context: context,
    Patterns: patterns.join(', '),
    Count: patterns.length
  }));
  
  
  return {
    weaver: patternWeaver,
    connector: PatternConnector,
    registry: PatternRegistry,
    utils: PatternUtils
  };
}

// ╭─────────────────────────────────────────────────────────────────╮
// │                    Pattern Examples                           │
// ╰─────────────────────────────────────────────────────────────────╯

/**
 * Example usage of the pattern system
 */
export const PatternExamples = {
  // Load and display data
  async loadAndDisplay(filePath: string) {
    const pipeline = PatternUtils.pipeline('LOADER', 'TABULAR');
    return await pipeline(filePath);
  },
  
  // Secure API call with timing
  async secureAPICall(endpoint: string) {
    const results = await PatternUtils.chain(
      { pattern: 'SECURE', context: { type: 'retrieve', service: 'api', name: 'token' } },
      { pattern: 'TIMING', context: () => fetch(endpoint) },
      { pattern: 'TABULAR', context: null }
    );
    return results;
  },
  
  // Build with versioning
  async buildWithVersion(config: any) {
    const results = await PatternUtils.parallel(
      { pattern: 'VERSIONER', context: { type: 'increment', version: config.version, release: 'patch' } },
      { pattern: 'BUILDER', context: config },
    );
    return results;
  },
  
  // Style processing pipeline
  async processStyles(cssFiles: string[]) {
    const results = [];
    for (const file of cssFiles) {
      const processed = await PatternUtils.chain(
        { pattern: 'LOADER', context: file },
        { pattern: 'STYLER', context: file },
      );
      results.push(processed);
    }
    return results;
  },
  
  // Shell command execution
  async executeShellCommands() {
    const results = await PatternUtils.parallel(
      { pattern: 'SHELL', context: { type: 'command', command: 'git status' } },
      { pattern: 'SHELL', context: { type: 'command', command: 'bun --version' } },
      { pattern: 'BUNX', context: { package: 'prettier', args: ['--version'] } }
    );
    return results;
  },
  
  // Development workflow automation
  async developmentWorkflow() {
    const pipeline = PatternUtils.pipeline('SHELL', 'BUNX', 'TIMING', 'TABULAR');
    return await pipeline({
      type: 'pipeline',
      commands: [
        'bun install',
        'bunx eslint . --fix',
        'bun test'
      ]
    });
  },
  
  // Deployment automation
  async deploymentAutomation() {
    const results = await PatternUtils.chain(
      { pattern: 'SHELL', context: { type: 'command', command: 'git pull' } },
      { pattern: 'BUNX', context: { package: 'typescript', args: ['--noEmit'] } },
      { pattern: 'BUILDER', context: { entrypoints: ['src/index.ts'], outdir: 'dist' } },
      { pattern: 'SHELL', context: { type: 'command', command: 'bun run deploy' } }
    );
    return results;
  },
  
  // Interactive CLI session
  async interactiveCLI() {
    const result = await patternWeaver.applyPattern('INTERACTIVE', {
      type: 'continuous',
      prompt: 'fire22> ',
      handler: async (input: string) => {
        if (input === 'status') {
          return await PatternUtils.chain(
            { pattern: 'SHELL', context: { type: 'command', command: 'git status' } },
            { pattern: 'TABULAR', context: [] }
          );
        }
        return `Executed: ${input}`;
      },
      validator: (input: string) => input.length > 0 && !input.includes('rm -rf')
    });
    return result;
  },
  
  // Stream processing pipeline
  async streamProcessing() {
    const result = await patternWeaver.applyPattern('STREAM', {
      processor: async (chunkText: string, chunk: Uint8Array, index: number) => {
        // Process each chunk - extract JSON data, count lines, etc.
        const lines = chunkText.split('\n');
        return {
          lineCount: lines.length,
          hasJSON: chunkText.includes('{'),
          size: chunk.length,
          processed: Date.now()
        };
      },
      encoding: 'utf8',
      bufferSize: 1024 * 1024 // 1MB
    });
    
    // Apply timing and tabular patterns to results
    const timing = await patternWeaver.applyPattern('TIMING', () => result);
    const table = patternWeaver.applyPattern('TABULAR', result.chunks);
    
    return { result, timing, table };
  },
  
  // CLI + Stream combined workflow
  async cliStreamWorkflow() {
    const results = await PatternUtils.parallel(
      { 
        pattern: 'INTERACTIVE', 
        context: { 
          type: 'single', 
          prompt: 'Enter command: ',
          handler: (input: string) => `Command received: ${input}`
        } 
      },
      { 
        pattern: 'STREAM', 
        context: { 
          processor: (text: string) => ({ wordCount: text.split(/\s+/).length })
        } 
      }
    );
    return results;
  },
  
  // File system validation example
  async validateProjectFiles() {
    const criticalFiles = [
      'package.json',
      'src/index.ts',
      'src/patterns/pattern-weaver.ts'
    ];
    
    const result = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'batch-check',
      paths: criticalFiles
    });
    
    // Display results with timing and table patterns
    const timing = await patternWeaver.applyPattern('TIMING', () => result);
    const table = patternWeaver.applyPattern('TABULAR', 
      result.results.map((r: any) => ({
        File: r.path,
        Status: r.exists ? '✅' : '❌',
        Size: `${(r.size / 1024).toFixed(1)}KB`
      }))
    );
    
    return { validation: result, timing, table };
  },
  
  // File information retrieval
  async getFileDetails(filePath: string) {
    const results = await PatternUtils.chain(
      { pattern: 'FILESYSTEM', context: { operation: 'info', path: filePath } },
      { pattern: 'TABULAR', context: [] }
    );
    return results;
  },
  
  // Combined file validation workflow
  async fileSystemWorkflow() {
    const results = await PatternUtils.parallel(
      { 
        pattern: 'FILESYSTEM', 
        context: { 
          operation: 'exists',
          paths: ['package.json', 'bunfig.toml', 'src/']
        } 
      },
      { 
        pattern: 'FILESYSTEM', 
        context: { 
          operation: 'validate',
          paths: ['src/index.ts', 'src/patterns/']
        } 
      }
    );
    
    // Display combined results
    const table = patternWeaver.applyPattern('TABULAR', results);
    return { results, table };
  },
  
  // String processing with utilities
  async processText(text: string) {
    const results = await PatternUtils.parallel(
      { 
        pattern: 'UTILITIES', 
        context: { 
          operation: 'stringWidth', 
          input: text,
          options: { countAnsiEscapeCodes: false }
        } 
      },
      { 
        pattern: 'UTILITIES', 
        context: { operation: 'stripANSI', input: text } 
      },
      { 
        pattern: 'UTILITIES', 
        context: { operation: 'escapeHTML', input: text } 
      }
    );
    
    return {
      original: text,
      width: results[0].result,
      stripped: results[1].result,
      escaped: results[2].result
    };
  },
  
  // UUID generation and comparison
  async uuidWorkflow() {
    const uuid1 = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'randomUUID',
      options: { encoding: 'hex' }
    });
    
    const uuid2 = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'randomUUID',
      options: { encoding: 'base64' }
    });
    
    const comparison = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'deepEquals',
      input: uuid1,
      options: { compareWith: uuid2 }
    });
    
    return { uuid1, uuid2, areEqual: comparison };
  },
  
  // Compression workflow
  async compressionWorkflow(data: string) {
    const buffer = Buffer.from(data);
    
    const results = await PatternUtils.chain(
      { pattern: 'UTILITIES', context: { operation: 'gzip', input: buffer } },
      { pattern: 'UTILITIES', context: { operation: 'gunzip', input: null } }, // result from previous
    );
    
    return {
      originalSize: buffer.length,
      compressedSize: results[0].result.length,
      compressionRatio: ((buffer.length - results[0].result.length) / buffer.length * 100).toFixed(2) + '%',
      decompressed: new TextDecoder().decode(results[1].result)
    };
  },
  
  // Development tools workflow
  async developmentUtilities() {
    const results = await PatternUtils.parallel(
      { pattern: 'UTILITIES', context: { operation: 'version' } },
      { pattern: 'UTILITIES', context: { operation: 'which', input: 'bun' } },
      { 
        pattern: 'UTILITIES', 
        context: { 
          operation: 'resolveSync', 
          input: './package.json',
          options: { root: process.cwd() }
        } 
      }
    );
    
    return {
      bunInfo: results[0].result,
      bunPath: results[1].result,
      packagePath: results[2].result
    };
  },
  
  // Memory analysis workflow  
  async memoryAnalysis(objects: any[]) {
    const memoryResults = [];
    
    for (const obj of objects) {
      const memory = await patternWeaver.applyPattern('UTILITIES', {
        operation: 'estimateMemory',
        input: obj
      });
      
      memoryResults.push({
        object: obj.constructor?.name || typeof obj,
        ...memory
      });
    }
    
    // Display in table format
    const table = patternWeaver.applyPattern('TABULAR', memoryResults);
    
    return { 
      individual: memoryResults,
      table,
      totalBytes: memoryResults.reduce((sum, r) => sum + r.bytes, 0)
    };
  },
  
  // Advanced table formatting examples
  async tableFormattingShowcase() {
    const sampleData = [
      { name: 'Alice', age: 30, city: 'New York', salary: 75000, department: 'Engineering' },
      { name: 'Bob', age: 25, city: 'San Francisco', salary: 85000, department: 'Engineering' },
      { name: 'Charlie', age: 35, city: 'Austin', salary: 65000, department: 'Marketing' },
      { name: 'Diana', age: 28, city: 'Seattle', salary: 90000, department: 'Engineering' },
      { name: 'Eve', age: 32, city: 'Boston', salary: 70000, department: 'Sales' }
    ];
    
    // Different table formatting approaches
    const results = {
      // Full table with colors
      fullTable: patternWeaver.applyPattern('TABULAR', {
        data: sampleData,
        options: { colors: true }
      }),
      
      // Only specific columns
      nameAndSalary: patternWeaver.applyPattern('TABULAR', {
        data: sampleData,
        properties: ['name', 'salary'],
        options: { colors: true }
      }),
      
      // Engineering department only
      engineeringOnly: patternWeaver.applyPattern('TABULAR', {
        data: sampleData.filter(person => person.department === 'Engineering'),
        properties: ['name', 'city', 'salary'],
        options: { colors: true }
      }),
      
      // Summary statistics
      departmentSummary: patternWeaver.applyPattern('TABULAR', {
        data: [
          { 
            department: 'Engineering', 
            count: sampleData.filter(p => p.department === 'Engineering').length,
            avgSalary: Math.round(sampleData.filter(p => p.department === 'Engineering')
              .reduce((sum, p) => sum + p.salary, 0) / 
              sampleData.filter(p => p.department === 'Engineering').length)
          },
          { 
            department: 'Marketing', 
            count: sampleData.filter(p => p.department === 'Marketing').length,
            avgSalary: Math.round(sampleData.filter(p => p.department === 'Marketing')
              .reduce((sum, p) => sum + p.salary, 0) / 
              sampleData.filter(p => p.department === 'Marketing').length)
          },
          { 
            department: 'Sales', 
            count: sampleData.filter(p => p.department === 'Sales').length,
            avgSalary: Math.round(sampleData.filter(p => p.department === 'Sales')
              .reduce((sum, p) => sum + p.salary, 0) / 
              sampleData.filter(p => p.department === 'Sales').length)
          }
        ],
        properties: ['department', 'count', 'avgSalary'],
        options: { colors: true }
      })
    };
    
    return results;
  },
  
  // Performance metrics table
  async performanceMetricsTable() {
    const metrics = [
      { operation: 'File Loading', time: '1.2ms', pattern: 'LOADER', status: '✅' },
      { operation: 'Shell Command', time: '45.8ms', pattern: 'SHELL', status: '✅' },
      { operation: 'String Processing', time: '0.03ms', pattern: 'UTILITIES', status: '✅' },
      { operation: 'Compression', time: '12.4ms', pattern: 'UTILITIES', status: '✅' },
      { operation: 'File System Check', time: '0.8ms', pattern: 'FILESYSTEM', status: '✅' }
    ];
    
    // Create different views of the performance data
    return {
      // All metrics
      allMetrics: patternWeaver.applyPattern('TABULAR', {
        data: metrics,
        options: { colors: true }
      }),
      
      // Just timing data
      timingOnly: patternWeaver.applyPattern('TABULAR', {
        data: metrics,
        properties: ['operation', 'time'],
        options: { colors: true }
      }),
      
      // Pattern usage summary
      patternSummary: patternWeaver.applyPattern('TABULAR', {
        data: [...new Set(metrics.map(m => m.pattern))].map(pattern => ({
          pattern,
          operations: metrics.filter(m => m.pattern === pattern).length,
          avgTime: metrics.filter(m => m.pattern === pattern)
            .reduce((sum, m) => sum + parseFloat(m.time), 0) / 
            metrics.filter(m => m.pattern === pattern).length + 'ms'
        })),
        options: { colors: true }
      })
    };
  },
  
  // File system analysis table
  async fileSystemAnalysisTable() {
    const files = [
      'package.json', 'src/index.ts', 'src/patterns/pattern-weaver.ts',
      'src/patterns/shell-weaver.ts', 'dashboard.html', 'schema.sql'
    ];
    
    const analysis: Array<{ file: string; path: string; size: string; type: string; extension: string; }> = [];
    
    // Analyze each file
    for (const file of files) {
      const info = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'info',
        path: file
      });
      
      if (info && info.exists) {
        analysis.push({
          file: info.name || file.split('/').pop() || file,
          path: file,
          size: `${(info.size / 1024).toFixed(1)}KB`,
          type: info.type || 'unknown',
          extension: info.extension || 'none'
        });
      }
    }
    
    return {
      // Full file analysis
      fullAnalysis: await patternWeaver.applyPattern('TABULAR', {
        data: analysis,
        options: { colors: true }
      }) as TabularResult,
      
      // Size summary only
      sizeSummary: await patternWeaver.applyPattern('TABULAR', {
        data: analysis,
        properties: ['file', 'size', 'type'],
        options: { colors: true }
      }) as TabularResult,
      
      // File type distribution
      typeDistribution: await patternWeaver.applyPattern('TABULAR', {
        data: [...new Set(analysis.map(a => a.extension))].map(ext => ({
          extension: ext,
          count: analysis.filter(a => a.extension === ext).length,
          totalSize: analysis.filter(a => a.extension === ext)
            .reduce((sum, a) => sum + parseFloat(a.size), 0).toFixed(1) + 'KB'
        })),
        options: { colors: true }
      }) as TabularResult
    };
  },
  
  // Advanced table processing showcase
  async advancedTableProcessing() {
    const salesData = [
      { rep: 'Alice', region: 'North', month: 'Jan', sales: 15000, commission: 1500 },
      { rep: 'Bob', region: 'South', month: 'Jan', sales: 12000, commission: 1200 },
      { rep: 'Charlie', region: 'East', month: 'Jan', sales: 18000, commission: 1800 },
      { rep: 'Alice', region: 'North', month: 'Feb', sales: 16000, commission: 1600 },
      { rep: 'Bob', region: 'South', month: 'Feb', sales: 14000, commission: 1400 },
      { rep: 'Charlie', region: 'East', month: 'Feb', sales: 19000, commission: 1900 },
      { rep: 'Diana', region: 'West', month: 'Jan', sales: 13000, commission: 1300 },
      { rep: 'Diana', region: 'West', month: 'Feb', sales: 15000, commission: 1500 }
    ];
    
    // 1. Filtered and sorted data
    const highPerformers = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      filter: { column: 'sales', value: 15000, operator: 'greater' },
      sort: { column: 'sales', direction: 'desc' },
      properties: ['rep', 'region', 'sales', 'commission'],
      theme: 'professional'
    });
    
    // 2. Aggregated data by region
    const regionSummary = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      aggregate: {
        groupBy: 'region',
        aggregations: [
          { column: 'sales', operation: 'sum' },
          { column: 'sales', operation: 'avg' },
          { column: 'commission', operation: 'sum' }
        ]
      },
      theme: 'colorful',
      sort: { column: 'sales_sum', direction: 'desc' }
    });
    
    // 3. Monthly comparison
    const monthlyComparison = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      aggregate: {
        groupBy: 'month',
        aggregations: [
          { column: 'sales', operation: 'sum' },
          { column: 'sales', operation: 'count' }
        ]
      },
      theme: 'dark'
    });
    
    // 4. Detailed analysis with metadata
    const detailedAnalysis = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'detailed',
      theme: 'default'
    }) as TabularResult;
    
    // 5. Export formats
    const csvExport = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'csv',
      properties: ['rep', 'region', 'sales']
    });
    
    const markdownExport = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'markdown',
      sort: { column: 'sales', direction: 'desc' },
      properties: ['rep', 'region', 'sales']
    });
    
    return {
      highPerformers,
      regionSummary,
      monthlyComparison,
      detailedAnalysis: {
        table: detailedAnalysis.table,
        metadata: detailedAnalysis.metadata,
        rowCount: detailedAnalysis.metadata.rowCount,
        columnStats: Object.entries(detailedAnalysis.metadata.statistics)
          .map(([col, stats]) => ({ column: col, ...stats }))
      },
      exports: {
        csv: csvExport,
        markdown: markdownExport
      }
    };
  },
  
  // Performance benchmarking table
  async performanceBenchmarkTable() {
    const benchmarks = [
      { operation: 'File Load', pattern: 'LOADER', time_ns: 1200000, memory_kb: 45 },
      { operation: 'String Width', pattern: 'UTILITIES', time_ns: 37090, memory_kb: 2 },
      { operation: 'Table Format', pattern: 'TABULAR', time_ns: 250000, memory_kb: 15 },
      { operation: 'Shell Execute', pattern: 'SHELL', time_ns: 45800000, memory_kb: 128 },
      { operation: 'File Exists', pattern: 'FILESYSTEM', time_ns: 800000, memory_kb: 1 },
      { operation: 'Compression', pattern: 'UTILITIES', time_ns: 12400000, memory_kb: 256 }
    ];
    
    // Performance analysis with different themes and formats
    const results = {
      // Fast operations only (< 1ms)
      fastOps: await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks,
        filter: { column: 'time_ns', value: 1000000, operator: 'less' },
        sort: { column: 'time_ns', direction: 'asc' },
        properties: ['operation', 'pattern', 'time_ns'],
        theme: 'professional'
      }),
      
      // Memory usage analysis
      memoryAnalysis: await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks,
        aggregate: {
          groupBy: 'pattern',
          aggregations: [
            { column: 'memory_kb', operation: 'avg' },
            { column: 'memory_kb', operation: 'sum' },
            { column: 'time_ns', operation: 'avg' }
          ]
        },
        sort: { column: 'memory_kb_avg', direction: 'desc' },
        theme: 'colorful'
      }),
      
      // Detailed performance report
      detailedReport: await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks.map(b => ({
          ...b,
          time_ms: (b.time_ns / 1000000).toFixed(3),
          efficiency: Math.round(1000000 / b.time_ns * 100) / 100
        })),
        format: 'detailed',
        properties: ['operation', 'pattern', 'time_ms', 'memory_kb', 'efficiency'],
        theme: 'minimal'
      }) as TabularResult
    };
    
    return results;
  },
  
  // Data analytics table with complex processing
  async dataAnalyticsTable() {
    const userData = Array.from({ length: 100 }, (_, i) => ({
      id: i + 1,
      name: `User${i + 1}`,
      age: Math.floor(Math.random() * 50) + 18,
      score: Math.floor(Math.random() * 100),
      category: ['A', 'B', 'C'][Math.floor(Math.random() * 3)],
      active: Math.random() > 0.3,
      joinDate: new Date(2020 + Math.floor(Math.random() * 4), 
                        Math.floor(Math.random() * 12),
                        Math.floor(Math.random() * 28)).toISOString().split('T')[0]
    }));
    
    const analytics = {
      // Top performers by category
      topPerformers: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        filter: { column: 'score', value: 80, operator: 'greater' },
        sort: { column: 'score', direction: 'desc' },
        properties: ['name', 'category', 'score', 'age'],
        theme: 'professional'
      }),
      
      // Category statistics
      categoryStats: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        aggregate: {
          groupBy: 'category',
          aggregations: [
            { column: 'score', operation: 'avg' },
            { column: 'score', operation: 'min' },
            { column: 'score', operation: 'max' },
            { column: 'age', operation: 'avg' },
            { column: 'id', operation: 'count' }
          ]
        },
        sort: { column: 'score_avg', direction: 'desc' },
        theme: 'colorful'
      }),
      
      // Active users analysis
      activeUsersAnalysis: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        filter: { column: 'active', value: true, operator: 'equals' },
        aggregate: {
          groupBy: 'category',
          aggregations: [
            { column: 'score', operation: 'avg' },
            { column: 'id', operation: 'count' }
          ]
        },
        theme: 'dark'
      }),
      
      // Export for external analysis
      csvExport: await patternWeaver.applyPattern('TABULAR', {
        data: userData.slice(0, 10), // Sample for demo
        format: 'csv',
        sort: { column: 'score', direction: 'desc' }
      }),
      
      // Comprehensive data report
      dataReport: await patternWeaver.applyPattern('TABULAR', {
        data: userData.slice(0, 20),
        format: 'detailed',
        sort: { column: 'score', direction: 'desc' }
      }) as TabularResult
    };
    
    return analytics;
  },
  
  // Large file processing with streaming
  async largeFileProcessing() {
    // Simulate processing a large file
    const largeFilePath = 'package.json'; // Use existing file as example
    
    const results = await PatternUtils.parallel(
      // Stream processing
      { 
        pattern: 'FILESYSTEM', 
        context: {
          operation: 'stream',
          path: largeFilePath,
          options: {
            chunkProcessor: async (chunk: Uint8Array, index: number) => {
              // Simulate complex processing
              await new Promise(resolve => setTimeout(resolve, 1));
              
              const text = Buffer.from(chunk).toString();
              return {
                index,
                processed: Date.now(),
                wordCount: text.split(/\s+/).filter(word => word.length > 0).length,
                charCount: text.length,
                hasSpecialChars: /[!@#$%^&*(),.?":{}|<>]/.test(text)
              };
            }
          }
        }
      },
      
      // File analysis  
      { 
        pattern: 'FILESYSTEM',
        context: {
          operation: 'streamAnalysis',
          path: largeFilePath
        }
      },
      
      // Performance timing
      { 
        pattern: 'TIMING',
      }
    );
    
    // Combine results with table formatting
    const [streamResult, analysisResult, timingResult] = results;
    
    // Create summary table
    const summaryData = [
      {
        Metric: 'File Size',
        Value: `${(streamResult.result.totalSize / 1024).toFixed(2)} KB`,
        Performance: streamResult.result.throughput || 'N/A'
      },
      {
        Metric: 'Total Chunks',
        Value: streamResult.result.totalChunks,
        Performance: streamResult.result.streamingTime
      },
      {
        Metric: 'Line Count',
        Value: analysisResult.result.analysis?.lineCount || 0,
        Performance: analysisResult.result.performance?.linesPerSecond + ' lines/sec' || 'N/A'
      },
      {
        Metric: 'Word Count', 
        Value: analysisResult.result.analysis?.wordCount || 0,
        Performance: analysisResult.result.performance?.processingTime || 'N/A'
      }
    ];
    
    const summaryTable = await patternWeaver.applyPattern('TABULAR', {
      data: summaryData,
      theme: 'professional',
      options: { colors: true }
    }) as TabularResult;
    
    return {
      streamResult: streamResult.result,
      analysisResult: analysisResult.result,
      summaryTable,
      performance: {
        streamingTime: streamResult.result.streamingTime,
        analysisTime: analysisResult.result.performance?.processingTime,
        totalThroughput: streamResult.result.throughput
      }
    };
  },
  
  // Combined streaming and compression workflow
  async streamingCompressionWorkflow() {
    const filePath = 'src/patterns/pattern-weaver.ts';
    
    // Stream the file and compress chunks
    const streamResult = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'stream',
      path: filePath,
      options: {
        chunkProcessor: async (chunk: Uint8Array, index: number) => {
          // Compress each chunk
          const compressed = await patternWeaver.applyPattern('UTILITIES', {
            operation: 'gzip',
            input: chunk
          });
          
          return {
            originalSize: chunk.length,
            compressedSize: compressed.length,
            compressionRatio: ((chunk.length - compressed.length) / chunk.length * 100).toFixed(2) + '%',
            chunkIndex: index
          };
        }
      }
    });
    
    // Analyze compression effectiveness
    if (streamResult.success) {
      const compressionData = streamResult.chunks
        .filter((chunk: any) => chunk.processed)
        .map((chunk: any) => chunk.processed);
      
      const compressionSummary = await patternWeaver.applyPattern('TABULAR', {
        data: compressionData,
        aggregate: {
          groupBy: 'chunkIndex',
          aggregations: [
            { column: 'originalSize', operation: 'sum' },
            { column: 'compressedSize', operation: 'sum' }
          ]
        },
        properties: ['chunkIndex', 'originalSize', 'compressedSize', 'compressionRatio'],
        theme: 'colorful',
        sort: { column: 'chunkIndex', direction: 'asc' }
      }) as TabularResult;
      
      return {
        streamingResult: streamResult,
        compressionAnalysis: compressionSummary,
        overallStats: {
          totalChunks: compressionData.length,
          totalOriginalSize: compressionData.reduce((sum: number, c: any) => sum + c.originalSize, 0),
          totalCompressedSize: compressionData.reduce((sum: number, c: any) => sum + c.compressedSize, 0),
          overallCompressionRatio: compressionData.length > 0 ? 
            ((compressionData.reduce((sum: number, c: any) => sum + c.originalSize, 0) - 
              compressionData.reduce((sum: number, c: any) => sum + c.compressedSize, 0)) /
             compressionData.reduce((sum: number, c: any) => sum + c.originalSize, 0) * 100).toFixed(2) + '%' : '0%'
        }
      };
    }
    
    return { error: 'Streaming failed', details: streamResult };
  },
  
  // Real-time file monitoring with streams
  async fileStreamMonitoring() {
    const monitorFiles = [
      'package.json',
      'src/index.ts'
    ];
    
    const monitoringResults = [];
    
    for (const filePath of monitorFiles) {
      // Get baseline analysis
      const baseline = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'streamAnalysis',
        path: filePath
      });
      
      // Simulate monitoring (in real app, this would be continuous)
      const monitoring = {
        file: filePath,
        baseline: baseline.success ? {
          size: baseline.fileInfo?.size,
          lines: baseline.analysis?.lineCount,
          words: baseline.analysis?.wordCount,
          patterns: baseline.analysis?.patterns,
          lastCheck: new Date().toISOString()
        } : null,
        status: baseline.success ? 'healthy' : 'error'
      };
      
      monitoringResults.push(monitoring);
    }
    
    // Create monitoring dashboard
    const monitoringTable = await patternWeaver.applyPattern('TABULAR', {
      data: monitoringResults.map(m => ({
        File: m.file.split('/').pop(),
        Status: m.status === 'healthy' ? '✅ Healthy' : '❌ Error',
        Size: m.baseline ? `${(m.baseline.size / 1024).toFixed(1)}KB` : 'N/A',
        Lines: m.baseline?.lines || 0,
        Words: m.baseline?.words || 0,
        LastCheck: m.baseline?.lastCheck.split('T')[1].split('.')[0] || 'N/A'
      })),
      properties: ['File', 'Status', 'Size', 'Lines', 'LastCheck'],
      theme: 'dark',
      options: { colors: true }
    }) as TabularResult;
    
    return {
      monitoring: monitoringResults,
      dashboard: monitoringTable,
      summary: {
        totalFiles: monitoringResults.length,
        healthyFiles: monitoringResults.filter(m => m.status === 'healthy').length,
        totalSize: monitoringResults
          .filter(m => m.baseline?.size)
          .reduce((sum, m) => sum + (m.baseline?.size || 0), 0),
        lastUpdate: new Date().toISOString()
      }
    };
  },
  // Advanced file streaming workflow
  async fileStreamingWorkflow() {
    
    // Test with the pattern-weaver.ts file itself
    const filePath = './src/patterns/pattern-weaver.ts';
    
    // Step 1: Get file information
    const fileInfo = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'info',
      path: filePath
    });
    
    const infoTable = await patternWeaver.applyPattern('TABULAR', {
      data: [
        { Property: 'Path', Value: filePath },
        { Property: 'Size', Value: `${(fileInfo.size / 1024).toFixed(2)} KB` },
        { Property: 'Type', Value: fileInfo.type || 'TypeScript' },
        { Property: 'Last Modified', Value: new Date(fileInfo.lastModified).toLocaleString() }
      ]
    }) as TabularResult;
    
    // Step 2: Stream with advanced analysis
    const streamResult = await patternWeaver.applyPattern('STREAM', {
      source: 'file',
      filePath,
      analysis: true,
      processor: async (text: string, chunk: Uint8Array, index: number) => {
        // Custom processing: Extract function names
        const functions = text.match(/(?:function|async\s+function)\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);
        const classes = text.match(/class\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);
        const interfaces = text.match(/interface\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);
        
        return {
          functions: functions?.length || 0,
          classes: classes?.length || 0,
          interfaces: interfaces?.length || 0,
          hasTypeScript: text.includes(': ') || text.includes('interface'),
          hasAsync: text.includes('async')
        };
      }
    });
    
    if (streamResult.success && streamResult.analysis) {
      const analysisTable = await patternWeaver.applyPattern('TABULAR', {
        data: [
          { Metric: 'Total Lines', Value: streamResult.analysis.lineCount.toLocaleString() },
          { Metric: 'Total Words', Value: streamResult.analysis.wordCount.toLocaleString() },
          { Metric: 'Total Characters', Value: streamResult.analysis.charCount.toLocaleString() },
          { Metric: 'Empty Lines', Value: `${streamResult.analysis.emptyLines} (${streamResult.analysis.emptyLinePercentage}%)` },
          { Metric: 'Max Line Length', Value: `${streamResult.analysis.maxLineLength} chars` },
          { Metric: 'Avg Words/Line', Value: streamResult.analysis.averageWordsPerLine },
          { Metric: 'Processing Time', Value: streamResult.processingTime },
          { Metric: 'Throughput', Value: streamResult.throughput }
        ]
      }) as TabularResult;
      
      // Pattern frequency analysis
      if (Object.keys(streamResult.analysis.patterns).length > 0) {
        const patterns = Object.entries(streamResult.analysis.patterns)
          .map(([pattern, count]) => ({
            Pattern: pattern,
            Occurrences: count,
            'Per 100 Lines': Math.round((count as number / streamResult.analysis.lineCount) * 100),
            Frequency: `${((count as number / streamResult.analysis.lineCount) * 100).toFixed(3)}%`
          }))
          .sort((a, b) => (b.Occurrences as number) - (a.Occurrences as number));
          
        const patternsTable = await patternWeaver.applyPattern('TABULAR', { data: patterns }) as TabularResult;
      }
      
      // Data type detection
      if (streamResult.analysis.dataTypes.length > 0) {
        const dataTable = await patternWeaver.applyPattern('TABULAR', {
          data: streamResult.analysis.dataTypes.map((type: string) => ({ 'Data Type': type, Status: '✅ Detected' }))
        }) as TabularResult;
      }
    }
    
    return streamResult;
  },
  
  // Large file processing demonstration
  async largeFileDemo() {
    
    // Simulate processing multiple files
    const files = [
      './src/patterns/pattern-weaver.ts',
      './src/patterns/pattern-connector.ts',
      './src/patterns/shell-weaver.ts'
    ];
    
    const results = [];
    
    for (const file of files) {
      
      const startTime = Bun.nanoseconds();
      
      // Get file info
      const info = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'info',
        path: file
      });
      
      if (!info.exists) {
        continue;
      }
      
      // Process with streaming
      const streamResult = await patternWeaver.applyPattern('STREAM', {
        source: 'file',
        filePath: file,
        analysis: true,
        bufferSize: 64 * 1024, // 64KB buffer
        chunkProcessor: async (chunk: Uint8Array, index: number) => {
          // Real-time chunk analysis
          const text = Buffer.from(chunk).toString('utf8');
          return {
            complexity: text.split('if').length + text.split('for').length + text.split('while').length,
            commentDensity: (text.match(/\/\*|\*\/|\/\//g) || []).length
          };
        }
      });
      
      const endTime = Bun.nanoseconds();
      const totalTime = (endTime - startTime) / 1_000_000;
      
      results.push({
        File: file.split('/').pop(),
        'Size (KB)': (info.size / 1024).toFixed(1),
        Lines: streamResult.analysis?.lineCount || 0,
        Chunks: streamResult.totalChunks,
        'Stream Time': streamResult.processingTime,
        'Total Time': `${totalTime.toFixed(2)}ms`,
        Status: streamResult.success ? '✅ Success' : '❌ Failed'
      });
    }
    
    // Display results table
    const summaryTable = await patternWeaver.applyPattern('TABULAR', { data: results }) as TabularResult;
    
    return results;
  },
  
  // Stream performance comparison
  async streamPerformanceTest() {
    
    const testFile = './src/patterns/pattern-weaver.ts';
    const tests = [
      { name: 'Basic Stream', config: { source: 'file', filePath: testFile } },
      { name: 'With Analysis', config: { source: 'file', filePath: testFile, analysis: true } },
      { name: 'With Processing', config: { 
        source: 'file', 
        filePath: testFile, 
        processor: async (text: string) => text.toUpperCase() 
      }},
      { name: 'Full Featured', config: { 
        source: 'file', 
        filePath: testFile, 
        analysis: true,
        processor: async (text: string) => text.toLowerCase(),
        chunkProcessor: async (chunk: Uint8Array, index: number) => ({ chunkSize: chunk.length, index })
      }}
    ];
    
    const performanceResults = [];
    
    for (const test of tests) {
      
      const result = await patternWeaver.applyPattern('STREAM', test.config);
      
      performanceResults.push({
        'Test Name': test.name,
        'Processing Time': result.processingTime,
        'Throughput': result.throughput,
        'Chunks Processed': result.totalChunks,
        'Total Size': `${(result.totalSize / 1024).toFixed(1)} KB`,
        'Success': result.success ? '✅' : '❌'
      });
    }
    
    const perfTable = await patternWeaver.applyPattern('TABULAR', { data: performanceResults }) as TabularResult;
    
    return performanceResults;
  },
  
  // File streaming with compression analysis
  async compressionStreamingWorkflow() {
    
    const files = [
      './src/patterns/pattern-weaver.ts',
      './package.json',
      './dashboard.html'
    ];
    
    const compressionResults = [];
    
    for (const file of files) {
      
      const streamResult = await patternWeaver.applyPattern('STREAM', {
        source: 'file',
        filePath: file,
        analysis: true,
        processor: async (text: string, chunk: Uint8Array, index: number) => {
          // Estimate compression potential
          const uniqueChars = new Set(text).size;
          const totalChars = text.length;
          const compressionRatio = uniqueChars / totalChars;
          const estimatedCompressedSize = Math.round(chunk.length * compressionRatio);
          
          return {
            uniqueCharacters: uniqueChars,
            compressionRatio: compressionRatio.toFixed(3),
            estimatedCompression: `${((1 - compressionRatio) * 100).toFixed(1)}%`,
            estimatedSize: estimatedCompressedSize
          };
        }
      });
      
      if (streamResult.success) {
        // Calculate compression estimates from processed data
        const avgCompression = streamResult.chunks
          .filter((c: any) => c.processed)
          .reduce((sum: number, c: any) => sum + parseFloat(c.processed.compressionRatio), 0) / 
          streamResult.chunks.filter((c: any) => c.processed).length;
        
        compressionResults.push({
          File: file.split('/').pop(),
          'Original Size': `${(streamResult.totalSize / 1024).toFixed(1)} KB`,
          'Data Types': streamResult.analysis?.dataTypes.join(', ') || 'Text',
          'Avg Compression Ratio': avgCompression?.toFixed(3) || 'N/A',
          'Est. Compression': avgCompression ? `${((1 - avgCompression) * 100).toFixed(1)}%` : 'N/A',
          'Processing Time': streamResult.processingTime
        });
      }
    }
    
    const compressionTable = await patternWeaver.applyPattern('TABULAR', { data: compressionResults }) as TabularResult;
    
    return compressionResults;
  }
};

// Auto-initialize on import (optional)
if (import.meta.main) {
  await initializePatterns();
}

// Default export
export default {
  weaver: patternWeaver,
  connector: PatternConnector,
  registry: PatternRegistry,
  utils: PatternUtils,
  examples: PatternExamples,
  initialize: initializePatterns
};
