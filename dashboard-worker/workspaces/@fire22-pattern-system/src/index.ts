// â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
// â”‚                    ğŸ•¸ï¸ PATTERN SYSTEM INDEX                     â”‚
// â”‚              The Central Hub of Pattern Weaving               â”‚
// â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

export { PatternWeaver, patternWeaver } from './pattern-weaver';
export { PatternConnector, withPattern, UsePattern } from './pattern-connector';
export { ShellPatternWeaver, shellWeaver } from './shell-weaver';

import { patternWeaver } from './pattern-weaver';
import PatternConnector from './pattern-connector';

// â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
// â”‚                   Pattern Registry                            â”‚
// â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

/**
 * Central registry of all patterns in the system
 * This creates the tapestry that connects everything
 */
export const PatternRegistry = {
  // Core patterns from Bun features
  patterns: {
    LOADER: 'ğŸ“‚ File Loading',
    STYLER: 'ğŸ¨ CSS Processing',
    TABULAR: 'ğŸ“Š Data Tables',
    SECURE: 'ğŸ” Secrets Management',
    TIMING: 'â±ï¸ Performance Measurement',
    BUILDER: 'ğŸ”¨ Build Process',
    VERSIONER: 'ğŸ“¦ Version Management',
    SHELL: 'ğŸš Shell Command Execution',
    BUNX: 'ğŸ“¦ Package Execution',
    INTERACTIVE: 'ğŸ¯ Interactive CLI',
    STREAM: 'ğŸŒŠ Stream Processing',
    FILESYSTEM: 'ğŸ“ File System Operations',
    UTILITIES: 'ğŸ”§ Utility Functions',
  },

  // Pattern connections map
  connections: new Map<string, string[]>([
    ['API', ['LOADER', 'SECURE', 'TIMING', 'TABULAR']],
    ['DATABASE', ['LOADER', 'TABULAR', 'TIMING']],
    ['BUILD', ['BUILDER', 'VERSIONER', 'TIMING', 'SHELL']],
    ['AUTH', ['SECURE', 'VERSIONER']],
    ['STYLES', ['STYLER', 'LOADER', 'BUILDER']],
    ['CONFIG', ['LOADER', 'VERSIONER']],
    ['MONITORING', ['TIMING', 'TABULAR']],
    ['REPORTS', ['TABULAR', 'TIMING', 'LOADER']],
    ['AUTOMATION', ['SHELL', 'BUNX', 'TIMING']],
    ['DEPLOYMENT', ['SHELL', 'BUILDER', 'SECURE', 'VERSIONER']],
    ['DEVELOPMENT', ['BUNX', 'SHELL', 'TIMING', 'TABULAR']],
    ['TOOLS', ['BUNX', 'SHELL', 'LOADER']],
    ['CLI', ['INTERACTIVE', 'SHELL', 'TABULAR', 'TIMING']],
    ['PIPES', ['STREAM', 'TIMING', 'TABULAR']],
    ['INPUT', ['INTERACTIVE', 'STREAM', 'SECURE']],
    ['VALIDATION', ['FILESYSTEM', 'TIMING', 'TABULAR']],
    ['FILES', ['FILESYSTEM', 'LOADER', 'SECURE']],
    ['TEXT', ['UTILITIES', 'TABULAR', 'TIMING']],
    ['COMPRESSION', ['UTILITIES', 'FILESYSTEM', 'TIMING']],
    ['DEBUGGING', ['UTILITIES', 'TIMING', 'TABULAR', 'INTERACTIVE']],
    ['PERFORMANCE', ['UTILITIES', 'TIMING', 'TABULAR']],
  ]),

  // Get patterns for a context
  getPatternsForContext(context: string): string[] {
    return this.connections.get(context.toUpperCase()) || [];
  },

  // Check if patterns are connected
  areConnected(pattern1: string, pattern2: string): boolean {
    for (const [_, patterns] of this.connections) {
      if (patterns.includes(pattern1) && patterns.includes(pattern2)) {
        return true;
      }
    }
    return false;
  },
};

// â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
// â”‚                    Pattern Utilities                          â”‚
// â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

/**
 * Utility functions for working with patterns
 */
export const PatternUtils = {
  /**
   * Apply multiple patterns in sequence
   */
  async chain(...patterns: Array<{ pattern: string; context: any }>) {
    const results = [];

    for (const { pattern, context } of patterns) {
      const result = await patternWeaver.applyPattern(pattern as any, context);
      results.push({ pattern, result });
    }

    return results;
  },

  /**
   * Apply patterns in parallel
   */
  async parallel(...patterns: Array<{ pattern: string; context: any }>) {
    const promises = patterns.map(({ pattern, context }) =>
      patternWeaver.applyPattern(pattern as any, context).then(result => ({ pattern, result }))
    );

    return await Promise.all(promises);
  },

  /**
   * Create a pattern pipeline
   */
  pipeline(...patterns: string[]) {
    return async (initialContext: any) => {
      let context = initialContext;

      for (const pattern of patterns) {
        context = await patternWeaver.applyPattern(pattern as any, context);
      }

      return context;
    };
  },

  /**
   * Measure pattern performance
   */
  async benchmark(pattern: string, context: any, iterations = 1000) {
    const timings: number[] = [];

    for (let i = 0; i < iterations; i++) {
      const start = Bun.nanoseconds();
      await patternWeaver.applyPattern(pattern as any, context);
      const end = Bun.nanoseconds();
      timings.push(end - start);
    }

    const avg = timings.reduce((a, b) => a + b, 0) / timings.length;
    const min = Math.min(...timings);
    const max = Math.max(...timings);

    return {
      pattern,
      iterations,
      avg: `${(avg / 1_000_000).toFixed(3)}ms`,
      min: `${(min / 1_000_000).toFixed(3)}ms`,
      max: `${(max / 1_000_000).toFixed(3)}ms`,
    };
  },
};

// â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
// â”‚                  Pattern Initialization                       â”‚
// â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

/**
 * Initialize the entire pattern system
 */
export async function initializePatterns() {
  console.log('â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®');
  console.log('â”‚                 ğŸ•¸ï¸ PATTERN WEAVER SYSTEM                â”‚');
  console.log('â”‚         Initializing Pattern Connections...            â”‚');
  console.log('â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯');
  console.log();

  // Initialize pattern connections
  await PatternConnector.initialize();

  // Display pattern registry
  console.log('\nğŸ“š Pattern Registry:');
  const registryTable = Object.entries(PatternRegistry.patterns).map(([key, name]) => ({
    Pattern: key,
    Description: name,
    Connections: PatternRegistry.connections.get(key.split('_')[0])?.length || 0,
  }));
  console.log(Bun.inspect.table(registryTable));

  // Show pattern contexts
  console.log('\nğŸ”— Pattern Contexts:');
  const contextTable = Array.from(PatternRegistry.connections.entries()).map(
    ([context, patterns]) => ({
      Context: context,
      Patterns: patterns.join(', '),
      Count: patterns.length,
    })
  );
  console.log(Bun.inspect.table(contextTable));

  console.log('\nâœ… Pattern system initialized successfully!');

  return {
    weaver: patternWeaver,
    connector: PatternConnector,
    registry: PatternRegistry,
    utils: PatternUtils,
  };
}

// â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
// â”‚                    Pattern Examples                           â”‚
// â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

/**
 * Example usage of the pattern system
 */
export const PatternExamples = {
  // Load and display data
  async loadAndDisplay(filePath: string) {
    const pipeline = PatternUtils.pipeline('LOADER', 'TABULAR');
    return await pipeline(filePath);
  },

  // Secure API call with timing
  async secureAPICall(endpoint: string) {
    const results = await PatternUtils.chain(
      { pattern: 'SECURE', context: { type: 'retrieve', service: 'api', name: 'token' } },
      { pattern: 'TIMING', context: () => fetch(endpoint) },
      { pattern: 'TABULAR', context: null }
    );
    return results;
  },

  // Build with versioning
  async buildWithVersion(config: any) {
    const results = await PatternUtils.parallel(
      {
        pattern: 'VERSIONER',
        context: { type: 'increment', version: config.version, release: 'patch' },
      },
      { pattern: 'BUILDER', context: config },
      { pattern: 'TIMING', context: () => console.log('Building...') }
    );
    return results;
  },

  // Style processing pipeline
  async processStyles(cssFiles: string[]) {
    const results = [];
    for (const file of cssFiles) {
      const processed = await PatternUtils.chain(
        { pattern: 'LOADER', context: file },
        { pattern: 'STYLER', context: file },
        { pattern: 'TIMING', context: () => console.log(`Processing ${file}`) }
      );
      results.push(processed);
    }
    return results;
  },

  // Shell command execution
  async executeShellCommands() {
    const results = await PatternUtils.parallel(
      { pattern: 'SHELL', context: { type: 'command', command: 'git status' } },
      { pattern: 'SHELL', context: { type: 'command', command: 'bun --version' } },
      { pattern: 'BUNX', context: { package: 'prettier', args: ['--version'] } }
    );
    return results;
  },

  // Development workflow automation
  async developmentWorkflow() {
    const pipeline = PatternUtils.pipeline('SHELL', 'BUNX', 'TIMING', 'TABULAR');
    return await pipeline({
      type: 'pipeline',
      commands: ['bun install', 'bunx eslint . --fix', 'bun test'],
    });
  },

  // Deployment automation
  async deploymentAutomation() {
    const results = await PatternUtils.chain(
      { pattern: 'SHELL', context: { type: 'command', command: 'git pull' } },
      { pattern: 'BUNX', context: { package: 'typescript', args: ['--noEmit'] } },
      { pattern: 'BUILDER', context: { entrypoints: ['src/index.ts'], outdir: 'dist' } },
      { pattern: 'SHELL', context: { type: 'command', command: 'bun run deploy' } }
    );
    return results;
  },

  // Interactive CLI session
  async interactiveCLI() {
    const result = await patternWeaver.applyPattern('INTERACTIVE', {
      type: 'continuous',
      prompt: 'fire22> ',
      handler: async (input: string) => {
        if (input === 'status') {
          return await PatternUtils.chain(
            { pattern: 'SHELL', context: { type: 'command', command: 'git status' } },
            { pattern: 'TABULAR', context: [] }
          );
        }
        return `Executed: ${input}`;
      },
      validator: (input: string) => input.length > 0 && !input.includes('rm -rf'),
    });
    return result;
  },

  // Stream processing pipeline
  async streamProcessing() {
    const result = await patternWeaver.applyPattern('STREAM', {
      processor: async (chunkText: string, chunk: Uint8Array, index: number) => {
        // Process each chunk - extract JSON data, count lines, etc.
        const lines = chunkText.split('\n');
        return {
          lineCount: lines.length,
          hasJSON: chunkText.includes('{'),
          size: chunk.length,
          processed: Date.now(),
        };
      },
      encoding: 'utf8',
      bufferSize: 1024 * 1024, // 1MB
    });

    // Apply timing and tabular patterns to results
    const timing = await patternWeaver.applyPattern('TIMING', () => result);
    const table = patternWeaver.applyPattern('TABULAR', result.chunks);

    return { result, timing, table };
  },

  // CLI + Stream combined workflow
  async cliStreamWorkflow() {
    const results = await PatternUtils.parallel(
      {
        pattern: 'INTERACTIVE',
        context: {
          type: 'single',
          prompt: 'Enter command: ',
          handler: (input: string) => `Command received: ${input}`,
        },
      },
      {
        pattern: 'STREAM',
        context: {
          processor: (text: string) => ({ wordCount: text.split(/\s+/).length }),
        },
      }
    );
    return results;
  },

  // File system validation example
  async validateProjectFiles() {
    const criticalFiles = ['package.json', 'src/index.ts', 'src/patterns/pattern-weaver.ts'];

    const result = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'batch-check',
      paths: criticalFiles,
    });

    // Display results with timing and table patterns
    const timing = await patternWeaver.applyPattern('TIMING', () => result);
    const table = patternWeaver.applyPattern(
      'TABULAR',
      result.results.map((r: any) => ({
        File: r.path,
        Status: r.exists ? 'âœ…' : 'âŒ',
        Size: `${(r.size / 1024).toFixed(1)}KB`,
      }))
    );

    return { validation: result, timing, table };
  },

  // File information retrieval
  async getFileDetails(filePath: string) {
    const results = await PatternUtils.chain(
      { pattern: 'FILESYSTEM', context: { operation: 'info', path: filePath } },
      { pattern: 'TIMING', context: () => console.log(`Getting info for ${filePath}`) },
      { pattern: 'TABULAR', context: [] }
    );
    return results;
  },

  // Combined file validation workflow
  async fileSystemWorkflow() {
    const results = await PatternUtils.parallel(
      {
        pattern: 'FILESYSTEM',
        context: {
          operation: 'exists',
          paths: ['package.json', 'bunfig.toml', 'src/'],
        },
      },
      {
        pattern: 'FILESYSTEM',
        context: {
          operation: 'validate',
          paths: ['src/index.ts', 'src/patterns/'],
        },
      }
    );

    // Display combined results
    const table = patternWeaver.applyPattern('TABULAR', results);
    return { results, table };
  },

  // String processing with utilities
  async processText(text: string) {
    const results = await PatternUtils.parallel(
      {
        pattern: 'UTILITIES',
        context: {
          operation: 'stringWidth',
          input: text,
          options: { countAnsiEscapeCodes: false },
        },
      },
      {
        pattern: 'UTILITIES',
        context: { operation: 'stripANSI', input: text },
      },
      {
        pattern: 'UTILITIES',
        context: { operation: 'escapeHTML', input: text },
      }
    );

    return {
      original: text,
      width: results[0].result,
      stripped: results[1].result,
      escaped: results[2].result,
    };
  },

  // UUID generation and comparison
  async uuidWorkflow() {
    const uuid1 = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'randomUUID',
      options: { encoding: 'hex' },
    });

    const uuid2 = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'randomUUID',
      options: { encoding: 'base64' },
    });

    const comparison = await patternWeaver.applyPattern('UTILITIES', {
      operation: 'deepEquals',
      input: uuid1,
      options: { compareWith: uuid2 },
    });

    return { uuid1, uuid2, areEqual: comparison };
  },

  // Compression workflow
  async compressionWorkflow(data: string) {
    const buffer = Buffer.from(data);

    const results = await PatternUtils.chain(
      { pattern: 'UTILITIES', context: { operation: 'gzip', input: buffer } },
      { pattern: 'UTILITIES', context: { operation: 'gunzip', input: null } }, // result from previous
      { pattern: 'TIMING', context: () => console.log('Compression cycle complete') }
    );

    return {
      originalSize: buffer.length,
      compressedSize: results[0].result.length,
      compressionRatio:
        (((buffer.length - results[0].result.length) / buffer.length) * 100).toFixed(2) + '%',
      decompressed: new TextDecoder().decode(results[1].result),
    };
  },

  // Development tools workflow
  async developmentUtilities() {
    const results = await PatternUtils.parallel(
      { pattern: 'UTILITIES', context: { operation: 'version' } },
      { pattern: 'UTILITIES', context: { operation: 'which', input: 'bun' } },
      {
        pattern: 'UTILITIES',
        context: {
          operation: 'resolveSync',
          input: './package.json',
          options: { root: process.cwd() },
        },
      }
    );

    return {
      bunInfo: results[0].result,
      bunPath: results[1].result,
      packagePath: results[2].result,
    };
  },

  // Memory analysis workflow
  async memoryAnalysis(objects: any[]) {
    const memoryResults = [];

    for (const obj of objects) {
      const memory = await patternWeaver.applyPattern('UTILITIES', {
        operation: 'estimateMemory',
        input: obj,
      });

      memoryResults.push({
        object: obj.constructor?.name || typeof obj,
        ...memory,
      });
    }

    // Display in table format
    const table = patternWeaver.applyPattern('TABULAR', memoryResults);

    return {
      individual: memoryResults,
      table,
      totalBytes: memoryResults.reduce((sum, r) => sum + r.bytes, 0),
    };
  },

  // Advanced table formatting examples
  async tableFormattingShowcase() {
    const sampleData = [
      { name: 'Alice', age: 30, city: 'New York', salary: 75000, department: 'Engineering' },
      { name: 'Bob', age: 25, city: 'San Francisco', salary: 85000, department: 'Engineering' },
      { name: 'Charlie', age: 35, city: 'Austin', salary: 65000, department: 'Marketing' },
      { name: 'Diana', age: 28, city: 'Seattle', salary: 90000, department: 'Engineering' },
      { name: 'Eve', age: 32, city: 'Boston', salary: 70000, department: 'Sales' },
    ];

    // Different table formatting approaches
    const results = {
      // Full table with colors
      fullTable: patternWeaver.applyPattern('TABULAR', {
        data: sampleData,
        options: { colors: true },
      }),

      // Only specific columns
      nameAndSalary: patternWeaver.applyPattern('TABULAR', {
        data: sampleData,
        properties: ['name', 'salary'],
        options: { colors: true },
      }),

      // Engineering department only
      engineeringOnly: patternWeaver.applyPattern('TABULAR', {
        data: sampleData.filter(person => person.department === 'Engineering'),
        properties: ['name', 'city', 'salary'],
        options: { colors: true },
      }),

      // Summary statistics
      departmentSummary: patternWeaver.applyPattern('TABULAR', {
        data: [
          {
            department: 'Engineering',
            count: sampleData.filter(p => p.department === 'Engineering').length,
            avgSalary: Math.round(
              sampleData
                .filter(p => p.department === 'Engineering')
                .reduce((sum, p) => sum + p.salary, 0) /
                sampleData.filter(p => p.department === 'Engineering').length
            ),
          },
          {
            department: 'Marketing',
            count: sampleData.filter(p => p.department === 'Marketing').length,
            avgSalary: Math.round(
              sampleData
                .filter(p => p.department === 'Marketing')
                .reduce((sum, p) => sum + p.salary, 0) /
                sampleData.filter(p => p.department === 'Marketing').length
            ),
          },
          {
            department: 'Sales',
            count: sampleData.filter(p => p.department === 'Sales').length,
            avgSalary: Math.round(
              sampleData
                .filter(p => p.department === 'Sales')
                .reduce((sum, p) => sum + p.salary, 0) /
                sampleData.filter(p => p.department === 'Sales').length
            ),
          },
        ],
        properties: ['department', 'count', 'avgSalary'],
        options: { colors: true },
      }),
    };

    return results;
  },

  // Performance metrics table
  async performanceMetricsTable() {
    const metrics = [
      { operation: 'File Loading', time: '1.2ms', pattern: 'LOADER', status: 'âœ…' },
      { operation: 'Shell Command', time: '45.8ms', pattern: 'SHELL', status: 'âœ…' },
      { operation: 'String Processing', time: '0.03ms', pattern: 'UTILITIES', status: 'âœ…' },
      { operation: 'Compression', time: '12.4ms', pattern: 'UTILITIES', status: 'âœ…' },
      { operation: 'File System Check', time: '0.8ms', pattern: 'FILESYSTEM', status: 'âœ…' },
    ];

    // Create different views of the performance data
    return {
      // All metrics
      allMetrics: patternWeaver.applyPattern('TABULAR', {
        data: metrics,
        options: { colors: true },
      }),

      // Just timing data
      timingOnly: patternWeaver.applyPattern('TABULAR', {
        data: metrics,
        properties: ['operation', 'time'],
        options: { colors: true },
      }),

      // Pattern usage summary
      patternSummary: patternWeaver.applyPattern('TABULAR', {
        data: [...new Set(metrics.map(m => m.pattern))].map(pattern => ({
          pattern,
          operations: metrics.filter(m => m.pattern === pattern).length,
          avgTime:
            metrics
              .filter(m => m.pattern === pattern)
              .reduce((sum, m) => sum + parseFloat(m.time), 0) /
              metrics.filter(m => m.pattern === pattern).length +
            'ms',
        })),
        options: { colors: true },
      }),
    };
  },

  // File system analysis table
  async fileSystemAnalysisTable() {
    const files = [
      'package.json',
      'src/index.ts',
      'src/patterns/pattern-weaver.ts',
      'src/patterns/shell-weaver.ts',
      'dashboard.html',
      'schema.sql',
    ];

    const analysis = [];

    // Analyze each file
    for (const file of files) {
      const info = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'info',
        path: file,
      });

      if (info && info.exists) {
        analysis.push({
          file: file.split('/').pop() || file,
          path: file,
          size: `${(info.size / 1024).toFixed(1)}KB`,
          type: info.type || 'unknown',
          extension: info.extension || 'none',
        });
      }
    }

    return {
      // Full file analysis
      fullAnalysis: patternWeaver.applyPattern('TABULAR', {
        data: analysis,
        options: { colors: true },
      }),

      // Size summary only
      sizeSummary: patternWeaver.applyPattern('TABULAR', {
        data: analysis,
        properties: ['file', 'size', 'type'],
        options: { colors: true },
      }),

      // File type distribution
      typeDistribution: patternWeaver.applyPattern('TABULAR', {
        data: [...new Set(analysis.map(a => a.extension))].map(ext => ({
          extension: ext,
          count: analysis.filter(a => a.extension === ext).length,
          totalSize:
            analysis
              .filter(a => a.extension === ext)
              .reduce((sum, a) => sum + parseFloat(a.size), 0)
              .toFixed(1) + 'KB',
        })),
        options: { colors: true },
      }),
    };
  },

  // Advanced table processing showcase
  async advancedTableProcessing() {
    const salesData = [
      { rep: 'Alice', region: 'North', month: 'Jan', sales: 15000, commission: 1500 },
      { rep: 'Bob', region: 'South', month: 'Jan', sales: 12000, commission: 1200 },
      { rep: 'Charlie', region: 'East', month: 'Jan', sales: 18000, commission: 1800 },
      { rep: 'Alice', region: 'North', month: 'Feb', sales: 16000, commission: 1600 },
      { rep: 'Bob', region: 'South', month: 'Feb', sales: 14000, commission: 1400 },
      { rep: 'Charlie', region: 'East', month: 'Feb', sales: 19000, commission: 1900 },
      { rep: 'Diana', region: 'West', month: 'Jan', sales: 13000, commission: 1300 },
      { rep: 'Diana', region: 'West', month: 'Feb', sales: 15000, commission: 1500 },
    ];

    // 1. Filtered and sorted data
    const highPerformers = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      filter: { column: 'sales', value: 15000, operator: 'greater' },
      sort: { column: 'sales', direction: 'desc' },
      properties: ['rep', 'region', 'sales', 'commission'],
      theme: 'professional',
    });

    // 2. Aggregated data by region
    const regionSummary = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      aggregate: {
        groupBy: 'region',
        aggregations: [
          { column: 'sales', operation: 'sum' },
          { column: 'sales', operation: 'avg' },
          { column: 'commission', operation: 'sum' },
        ],
      },
      theme: 'colorful',
      sort: { column: 'sales_sum', direction: 'desc' },
    });

    // 3. Monthly comparison
    const monthlyComparison = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      aggregate: {
        groupBy: 'month',
        aggregations: [
          { column: 'sales', operation: 'sum' },
          { column: 'sales', operation: 'count' },
        ],
      },
      theme: 'dark',
    });

    // 4. Detailed analysis with metadata
    const detailedAnalysis = (await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'detailed',
      theme: 'default',
    })) as TabularResult;

    // 5. Export formats
    const csvExport = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'csv',
      properties: ['rep', 'region', 'sales'],
    });

    const markdownExport = await patternWeaver.applyPattern('TABULAR', {
      data: salesData,
      format: 'markdown',
      sort: { column: 'sales', direction: 'desc' },
      properties: ['rep', 'region', 'sales'],
    });

    return {
      highPerformers,
      regionSummary,
      monthlyComparison,
      detailedAnalysis: {
        table: detailedAnalysis.table,
        metadata: detailedAnalysis.metadata,
        rowCount: detailedAnalysis.metadata.rowCount,
        columnStats: Object.entries(detailedAnalysis.metadata.statistics).map(([col, stats]) => ({
          column: col,
          ...stats,
        })),
      },
      exports: {
        csv: csvExport,
        markdown: markdownExport,
      },
    };
  },

  // Performance benchmarking table
  async performanceBenchmarkTable() {
    const benchmarks = [
      { operation: 'File Load', pattern: 'LOADER', time_ns: 1200000, memory_kb: 45 },
      { operation: 'String Width', pattern: 'UTILITIES', time_ns: 37090, memory_kb: 2 },
      { operation: 'Table Format', pattern: 'TABULAR', time_ns: 250000, memory_kb: 15 },
      { operation: 'Shell Execute', pattern: 'SHELL', time_ns: 45800000, memory_kb: 128 },
      { operation: 'File Exists', pattern: 'FILESYSTEM', time_ns: 800000, memory_kb: 1 },
      { operation: 'Compression', pattern: 'UTILITIES', time_ns: 12400000, memory_kb: 256 },
    ];

    // Performance analysis with different themes and formats
    const results = {
      // Fast operations only (< 1ms)
      fastOps: await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks,
        filter: { column: 'time_ns', value: 1000000, operator: 'less' },
        sort: { column: 'time_ns', direction: 'asc' },
        properties: ['operation', 'pattern', 'time_ns'],
        theme: 'professional',
      }),

      // Memory usage analysis
      memoryAnalysis: await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks,
        aggregate: {
          groupBy: 'pattern',
          aggregations: [
            { column: 'memory_kb', operation: 'avg' },
            { column: 'memory_kb', operation: 'sum' },
            { column: 'time_ns', operation: 'avg' },
          ],
        },
        sort: { column: 'memory_kb_avg', direction: 'desc' },
        theme: 'colorful',
      }),

      // Detailed performance report
      detailedReport: (await patternWeaver.applyPattern('TABULAR', {
        data: benchmarks.map(b => ({
          ...b,
          time_ms: (b.time_ns / 1000000).toFixed(3),
          efficiency: Math.round((1000000 / b.time_ns) * 100) / 100,
        })),
        format: 'detailed',
        properties: ['operation', 'pattern', 'time_ms', 'memory_kb', 'efficiency'],
        theme: 'minimal',
      })) as TabularResult,
    };

    return results;
  },

  // Data analytics table with complex processing
  async dataAnalyticsTable() {
    const userData = Array.from({ length: 100 }, (_, i) => ({
      id: i + 1,
      name: `User${i + 1}`,
      age: Math.floor(Math.random() * 50) + 18,
      score: Math.floor(Math.random() * 100),
      category: ['A', 'B', 'C'][Math.floor(Math.random() * 3)],
      active: Math.random() > 0.3,
      joinDate: new Date(
        2020 + Math.floor(Math.random() * 4),
        Math.floor(Math.random() * 12),
        Math.floor(Math.random() * 28)
      )
        .toISOString()
        .split('T')[0],
    }));

    const analytics = {
      // Top performers by category
      topPerformers: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        filter: { column: 'score', value: 80, operator: 'greater' },
        sort: { column: 'score', direction: 'desc' },
        properties: ['name', 'category', 'score', 'age'],
        theme: 'professional',
      }),

      // Category statistics
      categoryStats: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        aggregate: {
          groupBy: 'category',
          aggregations: [
            { column: 'score', operation: 'avg' },
            { column: 'score', operation: 'min' },
            { column: 'score', operation: 'max' },
            { column: 'age', operation: 'avg' },
            { column: 'id', operation: 'count' },
          ],
        },
        sort: { column: 'score_avg', direction: 'desc' },
        theme: 'colorful',
      }),

      // Active users analysis
      activeUsersAnalysis: await patternWeaver.applyPattern('TABULAR', {
        data: userData,
        filter: { column: 'active', value: true, operator: 'equals' },
        aggregate: {
          groupBy: 'category',
          aggregations: [
            { column: 'score', operation: 'avg' },
            { column: 'id', operation: 'count' },
          ],
        },
        theme: 'dark',
      }),

      // Export for external analysis
      csvExport: await patternWeaver.applyPattern('TABULAR', {
        data: userData.slice(0, 10), // Sample for demo
        format: 'csv',
        sort: { column: 'score', direction: 'desc' },
      }),

      // Comprehensive data report
      dataReport: (await patternWeaver.applyPattern('TABULAR', {
        data: userData.slice(0, 20),
        format: 'detailed',
        sort: { column: 'score', direction: 'desc' },
      })) as TabularResult,
    };

    return analytics;
  },

  // File streaming analysis workflow
  async fileStreamingWorkflow() {
    const testFiles = [
      'package.json',
      'src/index.ts',
      'src/patterns/pattern-weaver.ts',
      'src/patterns/shell-weaver.ts',
    ];

    const streamingResults = {};

    for (const filePath of testFiles) {
      // Basic file streaming
      const streamResult = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'stream',
        path: filePath,
        options: {
          chunkProcessor: (chunk: Uint8Array, index: number) => {
            // Process each chunk - count bytes, detect patterns, etc.
            const text = Buffer.from(chunk).toString();
            return {
              chunkIndex: index,
              size: chunk.length,
              hasJSON: text.includes('{'),
              hasImports: text.includes('import'),
              lineCount: text.split('\n').length - 1,
            };
          },
          bufferSize: 1024 * 1024, // 1MB limit
        },
      });

      // Advanced streaming analysis
      const analysisResult = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'streamAnalysis',
        path: filePath,
        options: {
          encoding: 'utf8',
        },
      });

      streamingResults[filePath] = {
        streaming: streamResult,
        analysis: analysisResult,
      };
    }

    return streamingResults;
  },

  // Large file processing with streaming
  async largeFileProcessing() {
    // Simulate processing a large file
    const largeFilePath = 'package.json'; // Use existing file as example

    const results = await PatternUtils.parallel(
      // Stream processing
      {
        pattern: 'FILESYSTEM',
        context: {
          operation: 'stream',
          path: largeFilePath,
          options: {
            chunkProcessor: async (chunk: Uint8Array, index: number) => {
              // Simulate complex processing
              await new Promise(resolve => setTimeout(resolve, 1));

              const text = Buffer.from(chunk).toString();
              return {
                index,
                processed: Date.now(),
                wordCount: text.split(/\s+/).length,
                charCount: text.length,
                hasSpecialChars: /[!@#$%^&*(),.?":{}|<>]/.test(text),
              };
            },
          },
        },
      },

      // File analysis
      {
        pattern: 'FILESYSTEM',
        context: {
          operation: 'streamAnalysis',
          path: largeFilePath,
        },
      },

      // Performance timing
      {
        pattern: 'TIMING',
        context: () => console.log('Processing large file...'),
      }
    );

    // Combine results with table formatting
    const [streamResult, analysisResult, timingResult] = results;

    // Create summary table
    const summaryData = [
      {
        Metric: 'File Size',
        Value: `${(streamResult.result.totalSize / 1024).toFixed(2)} KB`,
        Performance: streamResult.result.throughput || 'N/A',
      },
      {
        Metric: 'Total Chunks',
        Value: streamResult.result.totalChunks,
        Performance: streamResult.result.streamingTime,
      },
      {
        Metric: 'Line Count',
        Value: analysisResult.result.analysis?.lineCount || 0,
        Performance: analysisResult.result.performance?.linesPerSecond + ' lines/sec' || 'N/A',
      },
      {
        Metric: 'Word Count',
        Value: analysisResult.result.analysis?.wordCount || 0,
        Performance: analysisResult.result.performance?.processingTime || 'N/A',
      },
    ];

    const summaryTable = patternWeaver.applyPattern('TABULAR', {
      data: summaryData,
      theme: 'professional',
      options: { colors: true },
    });

    return {
      streamResult: streamResult.result,
      analysisResult: analysisResult.result,
      summaryTable,
      performance: {
        streamingTime: streamResult.result.streamingTime,
        analysisTime: analysisResult.result.performance?.processingTime,
        totalThroughput: streamResult.result.throughput,
      },
    };
  },

  // Combined streaming and compression workflow
  async streamingCompressionWorkflow() {
    const filePath = 'src/patterns/pattern-weaver.ts';

    // Stream the file and compress chunks
    const streamResult = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'stream',
      path: filePath,
      options: {
        chunkProcessor: async (chunk: Uint8Array, index: number) => {
          // Compress each chunk
          const compressed = await patternWeaver.applyPattern('UTILITIES', {
            operation: 'gzip',
            input: chunk,
          });

          return {
            originalSize: chunk.length,
            compressedSize: compressed.length,
            compressionRatio:
              (((chunk.length - compressed.length) / chunk.length) * 100).toFixed(2) + '%',
            chunkIndex: index,
          };
        },
      },
    });

    // Analyze compression effectiveness
    if (streamResult.success) {
      const compressionData = streamResult.chunks
        .filter(chunk => chunk.processed)
        .map(chunk => chunk.processed);

      const compressionSummary = patternWeaver.applyPattern('TABULAR', {
        data: compressionData,
        aggregate: {
          groupBy: 'chunkIndex',
          aggregations: [
            { column: 'originalSize', operation: 'sum' },
            { column: 'compressedSize', operation: 'sum' },
          ],
        },
        properties: ['chunkIndex', 'originalSize', 'compressedSize', 'compressionRatio'],
        theme: 'colorful',
        sort: { column: 'chunkIndex', direction: 'asc' },
      });

      return {
        streamingResult: streamResult,
        compressionAnalysis: compressionSummary,
        overallStats: {
          totalChunks: compressionData.length,
          totalOriginalSize: compressionData.reduce((sum, c) => sum + c.originalSize, 0),
          totalCompressedSize: compressionData.reduce((sum, c) => sum + c.compressedSize, 0),
          overallCompressionRatio:
            compressionData.length > 0
              ? (
                  ((compressionData.reduce((sum, c) => sum + c.originalSize, 0) -
                    compressionData.reduce((sum, c) => sum + c.compressedSize, 0)) /
                    compressionData.reduce((sum, c) => sum + c.originalSize, 0)) *
                  100
                ).toFixed(2) + '%'
              : '0%',
        },
      };
    }

    return { error: 'Streaming failed', details: streamResult };
  },

  // Real-time file monitoring with streams
  async fileStreamMonitoring() {
    const monitorFiles = ['package.json', 'src/index.ts'];

    const monitoringResults = [];

    for (const filePath of monitorFiles) {
      // Get baseline analysis
      const baseline = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'streamAnalysis',
        path: filePath,
      });

      // Simulate monitoring (in real app, this would be continuous)
      const monitoring = {
        file: filePath,
        baseline: baseline.success
          ? {
              size: baseline.fileInfo?.size,
              lines: baseline.analysis?.lineCount,
              words: baseline.analysis?.wordCount,
              patterns: baseline.analysis?.patterns,
              lastCheck: new Date().toISOString(),
            }
          : null,
        status: baseline.success ? 'healthy' : 'error',
      };

      monitoringResults.push(monitoring);
    }

    // Create monitoring dashboard
    const monitoringTable = patternWeaver.applyPattern('TABULAR', {
      data: monitoringResults.map(m => ({
        File: m.file.split('/').pop(),
        Status: m.status === 'healthy' ? 'âœ… Healthy' : 'âŒ Error',
        Size: m.baseline ? `${(m.baseline.size / 1024).toFixed(1)}KB` : 'N/A',
        Lines: m.baseline?.lines || 0,
        Words: m.baseline?.words || 0,
        LastCheck: m.baseline?.lastCheck.split('T')[1].split('.')[0] || 'N/A',
      })),
      properties: ['File', 'Status', 'Size', 'Lines', 'LastCheck'],
      theme: 'dark',
      options: { colors: true },
    });

    return {
      monitoring: monitoringResults,
      dashboard: monitoringTable,
      summary: {
        totalFiles: monitoringResults.length,
        healthyFiles: monitoringResults.filter(m => m.status === 'healthy').length,
        totalSize: monitoringResults
          .filter(m => m.baseline?.size)
          .reduce((sum, m) => sum + (m.baseline?.size || 0), 0),
        lastUpdate: new Date().toISOString(),
      },
    };
  },

  // â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
  // â”‚                File Streaming Analysis Examples             â”‚
  // â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

  // Advanced file streaming workflow
  async fileStreamingWorkflow() {
    console.log('ğŸŒŠ Advanced File Streaming Analysis');
    console.log('â•'.repeat(50));

    // Test with the pattern-weaver.ts file itself
    const filePath = './src/patterns/pattern-weaver.ts';

    // Step 1: Get file information
    const fileInfo = await patternWeaver.applyPattern('FILESYSTEM', {
      operation: 'info',
      path: filePath,
    });

    console.log('\nğŸ“Š File Information:');
    const infoTable = patternWeaver.applyPattern('TABULAR', [
      { Property: 'Path', Value: filePath },
      { Property: 'Size', Value: `${(fileInfo.size / 1024).toFixed(2)} KB` },
      { Property: 'Type', Value: fileInfo.type || 'TypeScript' },
      { Property: 'Last Modified', Value: new Date(fileInfo.lastModified).toLocaleString() },
    ]);
    console.log(infoTable.formatted);

    // Step 2: Stream with advanced analysis
    console.log('\nğŸ”„ Streaming with Analysis...');
    const streamResult = await patternWeaver.applyPattern('STREAM', {
      source: 'file',
      filePath,
      analysis: true,
      processor: async (text: string, chunk: Uint8Array, index: number) => {
        // Custom processing: Extract function names
        const functions = text.match(/(?:function|async\s+function)\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);
        const classes = text.match(/class\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);
        const interfaces = text.match(/interface\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g);

        return {
          functions: functions?.length || 0,
          classes: classes?.length || 0,
          interfaces: interfaces?.length || 0,
          hasTypeScript: text.includes(': ') || text.includes('interface'),
          hasAsync: text.includes('async'),
        };
      },
    });

    if (streamResult.success && streamResult.analysis) {
      console.log('\nğŸ“ˆ Analysis Results:');
      const analysisTable = patternWeaver.applyPattern('TABULAR', [
        { Metric: 'Total Lines', Value: streamResult.analysis.lineCount.toLocaleString() },
        { Metric: 'Total Words', Value: streamResult.analysis.wordCount.toLocaleString() },
        { Metric: 'Total Characters', Value: streamResult.analysis.charCount.toLocaleString() },
        {
          Metric: 'Empty Lines',
          Value: `${streamResult.analysis.emptyLines} (${streamResult.analysis.emptyLinePercentage}%)`,
        },
        { Metric: 'Max Line Length', Value: `${streamResult.analysis.maxLineLength} chars` },
        { Metric: 'Avg Words/Line', Value: streamResult.analysis.averageWordsPerLine },
        { Metric: 'Processing Time', Value: streamResult.processingTime },
        { Metric: 'Throughput', Value: streamResult.throughput },
      ]);
      console.log(analysisTable.formatted);

      // Pattern frequency analysis
      if (Object.keys(streamResult.analysis.patterns).length > 0) {
        console.log('\nğŸ” Code Pattern Analysis:');
        const patterns = Object.entries(streamResult.analysis.patterns)
          .map(([pattern, count]) => ({
            Pattern: pattern,
            Occurrences: count,
            'Per 100 Lines': Math.round(
              ((count as number) / streamResult.analysis.lineCount) * 100
            ),
            Frequency: `${(((count as number) / streamResult.analysis.lineCount) * 100).toFixed(3)}%`,
          }))
          .sort((a, b) => b.Occurrences - a.Occurrences);

        const patternsTable = patternWeaver.applyPattern('TABULAR', patterns);
        console.log(patternsTable.formatted);
      }

      // Data type detection
      if (streamResult.analysis.dataTypes.length > 0) {
        console.log('\nğŸ·ï¸  Detected Data Types:');
        const dataTable = patternWeaver.applyPattern(
          'TABULAR',
          streamResult.analysis.dataTypes.map(type => ({
            'Data Type': type,
            Status: 'âœ… Detected',
          }))
        );
        console.log(dataTable.formatted);
      }
    }

    return streamResult;
  },

  // Large file processing demonstration
  async largeFileDemo() {
    console.log('ğŸ—‚ï¸  Large File Processing Demo');
    console.log('â•'.repeat(40));

    // Simulate processing multiple files
    const files = [
      './src/patterns/pattern-weaver.ts',
      './src/patterns/pattern-connector.ts',
      './src/patterns/shell-weaver.ts',
    ];

    const results = [];

    for (const file of files) {
      console.log(`\nğŸ“ Processing: ${file.split('/').pop()}`);

      const startTime = Bun.nanoseconds();

      // Get file info
      const info = await patternWeaver.applyPattern('FILESYSTEM', {
        operation: 'info',
        path: file,
      });

      if (!info.exists) {
        console.log(`âŒ File not found: ${file}`);
        continue;
      }

      // Process with streaming
      const streamResult = await patternWeaver.applyPattern('STREAM', {
        source: 'file',
        filePath: file,
        analysis: true,
        bufferSize: 64 * 1024, // 64KB buffer
        chunkProcessor: async (chunk: Uint8Array, index: number) => {
          // Real-time chunk analysis
          const text = Buffer.from(chunk).toString('utf8');
          return {
            complexity:
              text.split('if').length + text.split('for').length + text.split('while').length,
            commentDensity: (text.match(/\/\*|\*\/|\/\//g) || []).length,
          };
        },
      });

      const endTime = Bun.nanoseconds();
      const totalTime = (endTime - startTime) / 1_000_000;

      results.push({
        File: file.split('/').pop(),
        'Size (KB)': (info.size / 1024).toFixed(1),
        Lines: streamResult.analysis?.lineCount || 0,
        Chunks: streamResult.totalChunks,
        'Stream Time': streamResult.processingTime,
        'Total Time': `${totalTime.toFixed(2)}ms`,
        Status: streamResult.success ? 'âœ… Success' : 'âŒ Failed',
      });
    }

    // Display results table
    console.log('\nğŸ“Š Processing Results Summary:');
    const summaryTable = patternWeaver.applyPattern('TABULAR', results);
    console.log(summaryTable.formatted);

    return results;
  },

  // Stream performance comparison
  async streamPerformanceTest() {
    console.log('âš¡ Stream Performance Testing');
    console.log('â•'.repeat(35));

    const testFile = './src/patterns/pattern-weaver.ts';
    const tests = [
      { name: 'Basic Stream', config: { source: 'file', filePath: testFile } },
      { name: 'With Analysis', config: { source: 'file', filePath: testFile, analysis: true } },
      {
        name: 'With Processing',
        config: {
          source: 'file',
          filePath: testFile,
          processor: async (text: string) => text.toUpperCase(),
        },
      },
      {
        name: 'Full Featured',
        config: {
          source: 'file',
          filePath: testFile,
          analysis: true,
          processor: async (text: string) => text.toLowerCase(),
          chunkProcessor: async (chunk: Uint8Array, index: number) => ({
            chunkSize: chunk.length,
            index,
          }),
        },
      },
    ];

    const performanceResults = [];

    for (const test of tests) {
      console.log(`\nğŸ” Testing: ${test.name}`);

      const result = await patternWeaver.applyPattern('STREAM', test.config);

      performanceResults.push({
        'Test Name': test.name,
        'Processing Time': result.processingTime,
        Throughput: result.throughput,
        'Chunks Processed': result.totalChunks,
        'Total Size': `${(result.totalSize / 1024).toFixed(1)} KB`,
        Success: result.success ? 'âœ…' : 'âŒ',
      });
    }

    console.log('\nğŸ“Š Performance Comparison:');
    const perfTable = patternWeaver.applyPattern('TABULAR', performanceResults);
    console.log(perfTable.formatted);

    return performanceResults;
  },

  // File streaming with compression analysis
  async compressionStreamingWorkflow() {
    console.log('ğŸ—œï¸  Compression-Aware Streaming');
    console.log('â•'.repeat(35));

    const files = ['./src/patterns/pattern-weaver.ts', './package.json', './dashboard.html'];

    const compressionResults = [];

    for (const file of files) {
      console.log(`\nğŸ“¦ Analyzing: ${file.split('/').pop()}`);

      const streamResult = await patternWeaver.applyPattern('STREAM', {
        source: 'file',
        filePath: file,
        analysis: true,
        processor: async (text: string, chunk: Uint8Array, index: number) => {
          // Estimate compression potential
          const uniqueChars = new Set(text).size;
          const totalChars = text.length;
          const compressionRatio = uniqueChars / totalChars;
          const estimatedCompressedSize = Math.round(chunk.length * compressionRatio);

          return {
            uniqueCharacters: uniqueChars,
            compressionRatio: compressionRatio.toFixed(3),
            estimatedCompression: `${((1 - compressionRatio) * 100).toFixed(1)}%`,
            estimatedSize: estimatedCompressedSize,
          };
        },
      });

      if (streamResult.success) {
        // Calculate compression estimates from processed data
        const avgCompression =
          streamResult.chunks
            .filter((c: any) => c.processed)
            .reduce((sum: number, c: any) => sum + parseFloat(c.processed.compressionRatio), 0) /
          streamResult.chunks.filter((c: any) => c.processed).length;

        compressionResults.push({
          File: file.split('/').pop(),
          'Original Size': `${(streamResult.totalSize / 1024).toFixed(1)} KB`,
          'Data Types': streamResult.analysis?.dataTypes.join(', ') || 'Text',
          'Avg Compression Ratio': avgCompression?.toFixed(3) || 'N/A',
          'Est. Compression': avgCompression
            ? `${((1 - avgCompression) * 100).toFixed(1)}%`
            : 'N/A',
          'Processing Time': streamResult.processingTime,
        });
      }
    }

    console.log('\nğŸ“Š Compression Analysis Results:');
    const compressionTable = patternWeaver.applyPattern('TABULAR', compressionResults);
    console.log(compressionTable.formatted);

    return compressionResults;
  },
};

// Auto-initialize on import (optional)
if (import.meta.main) {
  await initializePatterns();
}

// Default export
export default {
  weaver: patternWeaver,
  connector: PatternConnector,
  registry: PatternRegistry,
  utils: PatternUtils,
  examples: PatternExamples,
  initialize: initializePatterns,
};
